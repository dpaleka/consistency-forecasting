{
    "NegChecker": {
        "error": "RetryError[<Future at 0x7f51d5e22790 state=finished raised TypeError>]"
    },
    "AndChecker": {
        "overall": {
            "default": {
                "label": "AndChecker",
                "num_samples_including_errors": 300,
                "num_samples": 300,
                "num_violations": 32,
                "avg_violation": 0.336546,
                "avg_violation_no_outliers": 0.320273,
                "median_violation": 0.0
            },
            "frequentist": {
                "label": "AndChecker",
                "num_samples_including_errors": 300,
                "num_samples": 300,
                "num_violations": 32,
                "avg_violation": 1.057105,
                "avg_violation_no_outliers": 1.003036,
                "median_violation": 0.0
            },
            "default_scaled": {
                "label": "AndChecker",
                "num_samples_including_errors": 300,
                "num_samples": 300,
                "num_violations": 32,
                "avg_violation": 0.112182,
                "avg_violation_no_outliers": 0.106758,
                "median_violation": 0.0
            }
        }
    },
    "OrChecker": {
        "overall": {
            "default": {
                "label": "OrChecker",
                "num_samples_including_errors": 300,
                "num_samples": 300,
                "num_violations": 80,
                "avg_violation": 1.326188,
                "avg_violation_no_outliers": 1.312862,
                "median_violation": 0.0
            },
            "frequentist": {
                "label": "OrChecker",
                "num_samples_including_errors": 300,
                "num_samples": 300,
                "num_violations": 80,
                "avg_violation": 4.28302,
                "avg_violation_no_outliers": 4.250601,
                "median_violation": 0.0
            },
            "default_scaled": {
                "label": "OrChecker",
                "num_samples_including_errors": 300,
                "num_samples": 300,
                "num_violations": 80,
                "avg_violation": 0.442063,
                "avg_violation_no_outliers": 0.437621,
                "median_violation": 0.0
            }
        }
    },
    "AndOrChecker": {
        "overall": {
            "default": {
                "label": "AndOrChecker",
                "num_samples_including_errors": 300,
                "num_samples": 300,
                "num_violations": 104,
                "avg_violation": 1.378482,
                "avg_violation_no_outliers": 1.35067,
                "median_violation": 0.0
            },
            "frequentist": {
                "label": "AndOrChecker",
                "num_samples_including_errors": 300,
                "num_samples": 300,
                "num_violations": 104,
                "avg_violation": 4.251856,
                "avg_violation_no_outliers": 4.18563,
                "median_violation": 0.0
            },
            "default_scaled": {
                "label": "AndOrChecker",
                "num_samples_including_errors": 300,
                "num_samples": 300,
                "num_violations": 104,
                "avg_violation": 0.344621,
                "avg_violation_no_outliers": 0.337668,
                "median_violation": 0.0
            }
        }
    },
    "CondChecker": {
        "overall": {
            "default": {
                "label": "CondChecker",
                "num_samples_including_errors": 300,
                "num_samples": 300,
                "num_violations": 24,
                "avg_violation": 0.118649,
                "avg_violation_no_outliers": 0.10267,
                "median_violation": 0.0
            },
            "frequentist": {
                "label": "CondChecker",
                "num_samples_including_errors": 300,
                "num_samples": 300,
                "num_violations": 24,
                "avg_violation": 0.355745,
                "avg_violation_no_outliers": 0.283154,
                "median_violation": 0.0
            },
            "default_scaled": {
                "label": "CondChecker",
                "num_samples_including_errors": 300,
                "num_samples": 300,
                "num_violations": 24,
                "avg_violation": 0.03955,
                "avg_violation_no_outliers": 0.034223,
                "median_violation": 0.0
            }
        }
    },
    "ConsequenceChecker": {
        "error": "Expecting value: line 145 column 1 (char 792)"
    },
    "ParaphraseChecker": {
        "overall": {
            "default": {
                "label": "ParaphraseChecker",
                "num_samples_including_errors": 300,
                "num_samples": 300,
                "num_violations": 22,
                "avg_violation": 0.352577,
                "avg_violation_no_outliers": 0.336412,
                "median_violation": 0.0
            },
            "frequentist": {
                "label": "ParaphraseChecker",
                "num_samples_including_errors": 300,
                "num_samples": 300,
                "num_violations": 22,
                "avg_violation": 1.160375,
                "avg_violation_no_outliers": 1.106999,
                "median_violation": 0.0
            },
            "default_scaled": {
                "label": "ParaphraseChecker",
                "num_samples_including_errors": 300,
                "num_samples": 300,
                "num_violations": 22,
                "avg_violation": 0.176288,
                "avg_violation_no_outliers": 0.168206,
                "median_violation": 0.0
            }
        }
    },
    "CondCondChecker": {
        "overall": {
            "default": {
                "label": "CondCondChecker",
                "num_samples_including_errors": 300,
                "num_samples": 300,
                "num_violations": 22,
                "avg_violation": 0.026689,
                "avg_violation_no_outliers": 0.024542,
                "median_violation": 0.0
            },
            "frequentist": {
                "label": "CondCondChecker",
                "num_samples_including_errors": 300,
                "num_samples": 300,
                "num_violations": 26,
                "avg_violation": 0.061838,
                "avg_violation_no_outliers": 0.058904,
                "median_violation": 0.0
            },
            "default_scaled": {
                "label": "CondCondChecker",
                "num_samples_including_errors": 300,
                "num_samples": 300,
                "num_violations": 22,
                "avg_violation": 0.006672,
                "avg_violation_no_outliers": 0.006136,
                "median_violation": 0.0
            }
        }
    },
    "ExpectedEvidenceChecker": {
        "error": "Expecting value: line 139 column 1 (char 759)"
    },
    "aggregated": {
        "default": {
            "avg_violation": 0.6810831428571429
        },
        "frequentist": {
            "avg_violation": 2.1276987142857147
        },
        "default_scaled": {
            "avg_violation": 0.2186942857142857
        }
    },
    "forecaster": "ResolverBasedForecaster",
    "full_forecaster_config": {
        "resolver_model": "perplexity/llama-3.1-sonar-large-128k-online",
        "parsing_model": "gpt-4o-mini-2024-07-18",
        "n_attempts": 1,
        "hedging_on_sure": 0.001,
        "second_forecaster_config": {
            "model": "perplexity/llama-3.1-sonar-large-128k-online",
            "prompt": "\nYou are acting as an administrator for a forecasting platform.\nGiven the full data of a forecasting question, you must determine whether the question resolves YES or NO.\nIf YES, your final output should be 1. If NO, your final output should be 0.\n\nToday's date is 15 September 2024 or later. You can search for events that have happened before this date.\nThe question has resolved before your knowledge cutoff date; if there is evidence of a certain event happening, you should be able to find it.\nPlease do not make up events that have not been observed. \n\nIf you are unsure on the resolution of the question, output a probability between 0 and 1 based on your reasoning.\n\nThink everything through step-by-step before coming to a conclusion.\n",
            "parsing_model": "gpt-4o-mini-2024-07-18",
            "examples": [
                "Example(user=ForecastingQuestion(id=UUID('ad5d4590-490d-45cf-b82c-8438f70b921a'), title='Who will be the Democratic nominee for the 2020 US Presidential Election? (Hillary Clinton)', body='This question will resolve as **Yes** for the candidate below who is selected by the Democratic National Convention as the nominee for the 2020 US Presidential Election.  All other candidates will resolve as **No**.  This question is not restricted to the candidates currently below; other options may be added in the future.\\n\\nFor this question, it is not relevant who recieves the Democratic nomination on the day of the 2020 US election, it is solely determined by who is selected by the delegates of the [Democratic National Convention](https://en.wikipedia.org/wiki/Democratic_National_Convention).', resolution_date=datetime.datetime(2020, 8, 1, 4, 0), question_type='binary', data_source='metaculus', created_date=datetime.datetime(2019, 2, 22, 23, 40, 52), url=None, metadata=None, resolution=None), assistant=\"\\nLet's rephrase the resolution criteria: \\n- The question resolves as **Yes** if Hillary Clinton is selected as the Democratic nominee for the 2020 US Presidential Election;\\n- The question resolves as **No** otherwise.\\n\\nMy search says Joe Biden was selected as the Democratic nominee for the 2020 US Presidential Election.\\nThus, the question resolves as **No**, hence my final output is 0.\\n\")"
            ]
        }
    }
}