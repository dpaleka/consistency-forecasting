{"P":{"id":"5d8f3a24-b648-4e3c-8ded-e8b6eaf29493","title":"Will the average global CO₂ atmospheric concentration be less than 433.19 ppm over the 2024 to 2027 period?","body":"Resolution Criteria\nThis question resolves positively if the arithmetic mean of the annual mean CO₂ concentration over the 2024 to 2027 period (inclusive) is less than or equal to 433.19 ppm, as reported by Earth System Research Laboratory.","resolution_date":"2027-12-31T23:59:59Z","question_type":"binary","data_source":"synthetic_inst","url":null,"metadata":null,"resolution":null},"Q_and_not_P":{"id":"fb6af9ce-3603-439f-bb29-ecd25e615f22","title":"Will there be a 5-year period before 2100 with an average global temperature >3.6C warmer than the 1861-1880 baseline and an average global CO2 concentration of 433.19 ppm or more over the 2024 to 2027 period?","body":"Resolution Criteria\nThis combined question will resolve as Yes if both of the following conditions are met:\n\n1. There is a 5-year period before January 1, 2100, in which the average global temperature in each year is at least 3.6C greater than the average global temperature relative to the period 1861-1880, according to NASA. The data in the link is normalized relative to the 1951-1980 baseline, on which 1880 stands at -0.2C. Therefore, the critical value to look for with this specific NASA dataset will be 3.4C.\n\n2. The arithmetic mean of the annual mean CO2 concentration over the 2024 to 2027 period (inclusive) is greater than 433.19 ppm, as reported by Earth System Research Laboratory.\n\nIf NASA does not provide the data for a complete period up to 2100 (or a potential earlier resolution date), Metaculus may select an alternative credible source of data at their discretion for the first condition. The second condition will be based on reports by the Earth System Research Laboratory.","resolution_date":"2099-12-31T23:59:59Z","question_type":"binary","data_source":"synthetic_inst","url":null,"metadata":null,"resolution":null},"P_or_Q":{"id":"fb8bd3da-3a8f-4c0f-9cef-be3dbddfeb91","title":"Will either of the following occur: (a) the average global CO₂ atmospheric concentration be less than 433.19 ppm over the 2024 to 2027 period, or (b) there be a 5-year period before 2100 with an average global temperature >3.6˚C warmer than the 1861-1880 baseline?","body":"Resolution Criteria for (a): This question resolves positively if the arithmetic mean of the annual mean CO₂ concentration over the 2024 to 2027 period (inclusive) is less than or equal to 433.19 ppm, as reported by Earth System Research Laboratory.\n\nResolution Criteria for (b): This question will resolve as Yes if, before January 1, 2100, there is a 5-year period in which the average global temperature in each year is at least 3.6˚C greater than the average global temperature relative to the period 1861–1880, according to NASA. Note that the data in the link is normalised relative to the 1951-1980 baseline, on which 1880 stands at -0.2. Therefore, the critical value to look for with this specific NASA dataset will be 3.4˚C.\n\nIf NASA does not provide this data for a complete period up to 2100 (or a potential earlier resolution date), Metaculus may select an alternative credible source of data at their discretion.","resolution_date":"2099-12-31T23:59:59Z","question_type":"binary","data_source":"synthetic_inst","url":null,"metadata":null,"resolution":false},"metadata":{"base_sentences":{"P":{"id":"b6ea59a2-fa96-41a7-8484-4eba53141972","title":"Will the average global CO₂ atmospheric concentration be less than 433.19 ppm over the 2024 to 2027 period?","body":"Resolution Criteria\nThis question resolves positively if the arithmetic mean of the annual mean CO₂ concentration over the 2024 to 2027 period (inclusive) is less than or equal to 433.19 ppm, as reported by Earth System Research Laboratory.","resolution_date":"2027-12-31T23:59:59Z","question_type":"binary","data_source":"metaculus","url":"https://www.metaculus.com/questions/3742","metadata":{"topics":[],"background_info":"A Representative Concentration Pathway (RCP) is a greenhouse gas concentration trajectory adopted by the IPCC for its fifth Assessment Report (AR5) in 2014. These four pathways are prominently considered in IPPC climate modelling and research, which describe different climate futures, all of which are considered possible depending on how much greenhouse gases are emitted in the years to come.\nThe Representative Concentration Pathway (RCP) 8.5 corresponds to a high greenhouse gas emissions pathway compared to the scenario literature (IPCC 2008). The RCP8.5 is a so-called ‘baseline’ scenario that does not include any specific climate mitigation target. It combines assumptions about high population and relatively slow income growth with modest rates of technological change and energy intensity improvements, leading in the long term to high energy demand and GHG emissions in absence of climate change policies.\nPathway RCP4.5 limits mid-century (2046–2065) global mean temperature increase to 2.0°C with a likely range of 1.4°C to 2.6°C (95% confidence interval). Moreover, it limits end-of-century (2081–2100) global mean temperature increase to 3.7°C with a likely range of 2.6°C to 4.8°C (95% confidence interval) (IPPC, 2013).\nOver the 2022 to 2025 period (inclusive), the RCP8.5 corresponds to an average of 426.63 parts-per-million (ppm) of global CO₂ atmospheric concentration per year (Meinshausen et al. 2011). Over the 2027 to 2030 period, it corresponds to and average of 440.01 ppm of global CO₂ atmospheric concentration per year (ibid.).\nData\nData on global CO₂ atmospheric concentration may be found here.\nData on atmospheric concentration along RCP pathways may be found here. It may also be downloaded from here.\n"},"resolution":null},"Q":{"id":"0fa3b86f-9b29-4c19-84f3-217255d5fb6e","title":"Before 2100, will there be a 5-year period with an average global temperature >3.6˚C warmer than the 1861-1880 baseline?","body":"Resolution Criteria\nThis question will resolve as Yes if, before January 1, 2100, there is a 5-year period in which the average global temperature in each year is at least 3.6˚C greater than the average global temperature relative to the period 1861–1880, according to NASA. Note that the data in the link is normalised relative to the 1951-1980 baseline, on which 1880 stands at -0.2. Therefore, the critical value to look for with this specific NASA dataset will be 3.4˚C.\nIf NASA does not provide this data for a complete period up to 2100 (or a potential earlier resolution date), Metaculus may select an alternative credible source of data at their discretion\n","resolution_date":"2099-12-31T23:59:59Z","question_type":"binary","data_source":"metaculus","url":"https://www.metaculus.com/questions/1539","metadata":{"topics":[],"background_info":"Without additional efforts to reduce GHG emissions beyond those in place today, global emissions growth is expected to persist, driven by growth in global population and economic activities. Global mean surface temperature increases in 2100 in baseline scenarios—those without additional mitigation—range from 3.7°C to 4.8°C above the average for 1850–1900 for a median climate response.\nGiven these estimates of the baseline scenarios of unmitigated emissions, studies exploring particular effort-sharing mitigation frameworks, have estimated substantial global financial flows associated with mitigation in scenarios to limit warming during the 21st century to less than 2°C. But there is also a non-negligible chance that unmitigated emissions will lead to global temperature increases much higher than the median estimated outcome. More generally, estimates of temperature increases resulting from greenhouse emissions have a “fat” right tail, meaning that there is a low, but non-negligible chance of very high temperature increases.\nIn particular, it has been argued that there is a decent chance that the unmitigated emissions might result in a >6.4ºC change in global mean surface temperature. Then, even with the systems to reduce temperatures by 2.8ºC (as might be required in baseline scenarios to achieve the 2ºC target), mean global temperature might be still be at least as high as 3.6ºC, despite substantial mitigation efforts.\nThe estimated humanitarian impacts of climate changes are likely highly nonlinear: marginal temperature increases are expected to cause more damage at already-increased temperatures (i.e. going from 3ºC to 4ºC is expected to be significantly worse than going from 1ºC to 2ºC). According to the IPCC's 2014 report,\nThe risks associated with temperatures at or above 4°C include severe and widespread impacts on unique and threatened systems, substantial species extinction, large risks to global and regional food security, consequential constraints on common human activities, increased likelihood of triggering tipping points (critical thresholds) and limited potential for adaptation in some cases.\n"},"resolution":null}},"relevance":{"reasons":["Both questions are related to climate change and its impacts.","The concentration of CO₂ in the atmosphere is a significant driver of global temperature increases.","Understanding the relationship between CO₂ levels and temperature increases can help in climate modeling and policy-making."],"conclusion":"The logical combination of these questions is relevant and meaningful.","score":9.0}}}
{"P":{"id":"9668e140-1003-45a2-8766-3348e8d855a2","title":"Who will be the Democratic nominee for the 2024 US Presidential Election? (Joe Biden)","body":"Resolution Criteria\nThis question will resolve as Yes for the candidate below who is selected by the Democratic National Convention as the nominee for the 2024 US Presidential Election. All other candidates not selected by the DNC will resolve as No, for whatever reason (if they are deceased, choose not to seek nomination, withdraw candidacy, are not selected by delegates, or any other reason). This question is not restricted to the candidates currently below; other options may be added in the future.\nFor this question, it is not relevant who recieves the Democratic nomination on the day of the 2024 US election, it is solely determined by who is selected by the delegates of the Democratic National Convention.\nFine Print\nIf there is no Democratic National Convention convened in the year 2024, or that convention does not select a nominee, this question will resolve as Ambiguous.\n","resolution_date":"2024-12-31T23:59:59Z","question_type":"binary","data_source":"synthetic_inst","url":null,"metadata":null,"resolution":null},"Q_and_not_P":{"id":"88865cba-96db-488d-bf91-ba99577d9d09","title":"Will the first AGI be developed by a government project and Joe Biden not be the Democratic nominee for the 2024 US Presidential Election?","body":"Resolution Criteria\nThis question will resolve positively if both of the following conditions are met:\n\n1. The AI system that resolves the question 'Date first AGI is publicly known' was developed by a research group working for a government project. If the respective AI system is developed under a collaborative effort between two or more different institutions, the question resolves positively for both. For example, if OpenAI and UC Berkeley's CHAI had joined forces for the responsible project, this would count for both for-profit corporation and university.\n\n2. Any candidate other than Joe Biden is selected by the Democratic National Convention as the nominee for the 2024 US Presidential Election. Joe Biden, if not selected by the DNC, will resolve as Yes, for whatever reason (if he is deceased, chooses not to seek nomination, withdraws candidacy, is not selected by delegates, or any other reason). This question is not restricted to the candidates currently below; other options may be added in the future. It is solely determined by who is selected by the delegates of the Democratic National Convention.\n\nIf there is no Democratic National Convention convened in the year 2024, or that convention does not select a nominee, or if the AI system that resolves the question 'Date first AGI is publicly known' was not developed by a research group working for a government project, this question will resolve as No.\n\nSister questions\nNationalized organization develops first AGI\nNon-profit organization develops first AGI\nUniversity group develops first AGI\n[Corporation develops first AGI](https://www.metaculus.com/questions/8324/corp…)","resolution_date":"2099-12-31T23:59:59Z","question_type":"binary","data_source":"synthetic_inst","url":null,"metadata":null,"resolution":null},"P_or_Q":{"id":"04c9dc6f-4c6f-4418-9b3c-288065e382b2","title":"Will either Joe Biden be the Democratic nominee for the 2024 US Presidential Election or the research group responsible for developing the first AGI be part of a government project?","body":"Resolution Criteria for Joe Biden as Democratic nominee:\nThis question will resolve as Yes if Joe Biden is selected by the Democratic National Convention as the nominee for the 2024 US Presidential Election. It will resolve as No for any other candidate not selected by the DNC, for any reason (e.g., not seeking nomination, withdrawal, not selected by delegates, etc.). If no Democratic National Convention is convened in 2024, or if the convention does not select a nominee, this question will resolve as Ambiguous.\n\nResolution Criteria for AGI development by a government project:\nThis question will resolve positively if the AI system that resolves the question 'Date first AGI is publicly known' was developed by a research group working for a government project. If the AI system is developed under a collaborative effort between two or more different institutions, the question resolves positively for both. For example, if OpenAI and UC Berkeley's CHAI had joined forces for the responsible project, this would count for both for-profit corporation and university.\n\nThis combined question will resolve as Yes if either of the above conditions is met.","resolution_date":"2099-12-31T23:59:59Z","question_type":"binary","data_source":"synthetic_inst","url":null,"metadata":null,"resolution":false},"metadata":{"base_sentences":{"P":{"id":"a32bd8b2-9164-4493-a26d-c1c17d5a4ced","title":"Who will be the Democratic nominee for the 2024 US Presidential Election? (Joe Biden)","body":"Resolution Criteria\nThis question will resolve as Yes for the candidate below who is selected by the Democratic National Convention as the nominee for the 2024 US Presidential Election. All other candidates not selected by the DNC will resolve as No, for whatever reason (if they are deceased, choose not to seek nomination, withdraw candidacy, are not selected by delegates, or any other reason). This question is not restricted to the candidates currently below; other options may be added in the future.\nFor this question, it is not relevant who recieves the Democratic nomination on the day of the 2024 US election, it is solely determined by who is selected by the delegates of the Democratic National Convention.\nFine Print\nIf there is no Democratic National Convention convened in the year 2024, or that convention does not select a nominee, this question will resolve as Ambiguous.\n","resolution_date":"2024-12-31T23:59:59Z","question_type":"binary","data_source":"metaculus","url":"https://www.metaculus.com/questions/5712","metadata":{"topics":[],"background_info":"Joe Biden won the 2020 US Presidential Election against incumbent President Donald Trump. Biden has since expressed his intention multiple times of running for re-election, particularly if the Republican party nominated Donald Trump again. However, a March 2022 poll found that 52% of Americans expected Biden not to run for re-election, versus 29% who expected that he would. Biden's approval rating has remained from 45% to 40% from September 2021 to June 2022, and the US Inflation rate reached 8.5% in 2022.\nVice President Kamala Harris, often speculated as being likely to run in 2024, has had a net -10% approval rating from January to June 2022. As of June 2022, no other candidates have expressed intent to run, and no candidate (besides Harris), stands out in early polling.\nThe New York Times reported in June 2022 that many top Democrat officials expressed (off the record) concerns about a Biden re-election campaign, and uncertainty about selecting an alternative nominee.\n"},"resolution":null},"Q":{"id":"f11647ee-9679-4de0-8d84-05b86bbe9c05","title":"Will the research group that is responsible for developing the first AGI be part of a government project?","body":"Resolution Criteria\nThis question will resolve positively if the AI system that resolves the question Date first AGI is publicly known. was developed by a research group working for a government project.\nIf the respective AI system is developed under a collaborative effort between two or more different institutions, the question resolves positively for both. For example, if OpenAI and UC Berkeley's CHAI had joined forces for the responsible project, this would count for both for-profit corporation and university.\nSister questions\nNationalized organization develops first AGI\nNon-profit organization develops first AGI\nUniversity group develops first AGI\n[Corporation develops first AGI](https://www.metaculus.com/questions/8324/corp…\n","resolution_date":"2099-12-31T23:59:59Z","question_type":"binary","data_source":"metaculus","url":"https://www.metaculus.com/questions/8327","metadata":{"topics":[],"background_info":"The question Date first AGI is publicly known. asks When will the first AGI be first developed and demonstrated?.\nToday, research groups at both for-profit corporations and universities are working on developing general reasoning systems. Other possible institutions might be nationalized corporations, governments generally, and non-profit organizations."},"resolution":null}},"relevance":{"reasons":["The Democratic nominee for the 2024 US Presidential Election could influence government policies, including funding and support for AI research.","If Joe Biden is the nominee and potentially wins the election, his administration's stance on AI research and development could impact whether AGI development is part of a government project.","The political climate and priorities set by the Democratic nominee could affect the allocation of resources and the direction of AI research."],"conclusion":"There are plausible reasons to consider the logical combination of these questions, as the political leadership could influence the development of AGI.","score":6.0}}}
{"P":{"id":"18afa468-833e-4e29-b9d6-d602fe723968","title":"Will the US Supreme Court change its membership size before 2050?","body":"Resolution Criteria\nThis question will resolve as Yes if the US Supreme Court officially changes its regular number of sitting justices above or below 9 members at any point between January 1, 2020 to January 1, 2050.\nExpected vacancies and arrivals of justices (retirements, deaths, and absences for health reasons) are not sufficient to resolve the question\n","resolution_date":"2049-12-31T23:59:59Z","question_type":"binary","data_source":"synthetic_inst","url":null,"metadata":null,"resolution":null},"Q_and_not_P":{"id":"31956d5d-a8fa-481d-ac39-c1920488964b","title":"Will both the following conditions be met: (1) armed conflicts between the United States and the People's Republic of China lead to at least 100 deaths before 2050, and (2) the US Supreme Court maintains its membership size at exactly 9 members throughout the period until 2050?","body":"Resolution Criteria\nThis question will resolve as Yes if both of the following conditions are met:\n\n(1) At any time between January 1, 2021 to January 1, 2050, either of the following occur:\n- There are at least three credible government sources reporting at least one exchange of weapon fire between the national military forces or law enforcement personnel of the United States and the People's Republic of China causing a total of at least 100 deaths.\n- There are at least three credible news reports that at least one exchange of weapon fire between the national military forces or law enforcement personnel of the United States and the People's Republic of China causing a total of at least 100 deaths.\nThese 100 deaths do not have to occur in the same conflict or the same year; it is sufficient for multiple separate events to reach a total of 100 deaths in this period.\n\n(2) The US Supreme Court does not officially change its regular number of sitting justices from 9 members at any point between January 1, 2020 to January 1, 2050.\nExpected vacancies and arrivals of justices (retirements, deaths, and absences for health reasons) will not be considered as changes in the number of sitting justices for the purpose of this question.\n\nThis question will resolve as No if either one of the conditions is not met.","resolution_date":"2049-12-31T23:59:59Z","question_type":"binary","data_source":"synthetic_inst","url":null,"metadata":null,"resolution":null},"P_or_Q":{"id":"15da3ff4-51be-4761-bfa2-20ceb836ad2d","title":"Will either of the following occur before 2050: (a) the US Supreme Court changes its membership size, or (b) armed conflicts between the United States and the People's Republic of China lead to at least 100 deaths?","body":"Resolution Criteria for each part:\n\n(a) This question will resolve as Yes if the US Supreme Court officially changes its regular number of sitting justices above or below 9 members at any point between January 1, 2020 to January 1, 2050. Expected vacancies and arrivals of justices (retirements, deaths, and absences for health reasons) are not sufficient to resolve the question.\n\n(b) This question will resolve as Yes if, at any time between January 1, 2021 to January 1, 2050, either of the following occur:\n- There are at least three credible government sources reporting at least one exchange of weapon fire between the national military forces or law enforcement personnel of the United States and the People's Republic of China causing a total of at least 100 deaths.\n- There are at least three credible news reports that at least one exchange of weapon fire between the national military forces or law enforcement personnel of the United States and the People's Republic of China causing a total of at least 100 deaths.\nThese 100 deaths do not have to occur in the same conflict or the same year; it is sufficient for multiple separate events to reach a total of 100 deaths in this period.\nThis question will resolves as No otherwise.\nIn the context of this question, an armed conflict will be defined as a dispute that concerns a government and/or territory where the use of armed force between two parties, of which at least one is the government of a state, results in an exchange of weapon fire or detonations.","resolution_date":"2049-12-31T23:59:59Z","question_type":"binary","data_source":"synthetic_inst","url":null,"metadata":null,"resolution":false},"metadata":{"base_sentences":{"P":{"id":"8183738a-e1fc-465f-bacc-e75c40d8e6d1","title":"Will the US Supreme Court change its membership size before 2050?","body":"Resolution Criteria\nThis question will resolve as Yes if the US Supreme Court officially changes its regular number of sitting justices above or below 9 members at any point between January 1, 2020 to January 1, 2050.\nExpected vacancies and arrivals of justices (retirements, deaths, and absences for health reasons) are not sufficient to resolve the question\n","resolution_date":"2049-12-31T23:59:59Z","question_type":"binary","data_source":"metaculus","url":"https://www.metaculus.com/questions/3617","metadata":{"topics":[],"background_info":"The US supreme court currently has a fixed size of 9 members, but it hasn't always been this way. It takes only an act of congress to change the size of the court. The president Franklin D. Roosevelt famously failed to increase the size of the court despite his party having a supermajority in congress."},"resolution":null},"Q":{"id":"185f507e-e5d2-4b50-84ef-d0c535c1bdb4","title":"Will armed conflicts between the United States and the People's Republic of China lead to at least 100 deaths before 2050?","body":"Resolution Criteria\nThis question will resolve as Yes if, at any time between January 1, 2021 to January 1, 2050, either of the following occur:\nThere are at least three credible government sources reporting at least one exchange of weapon fire between the national military forces or law enforcement personnel of the United States and the People's Republic of China causing a total of at least 100 deaths.\nThere are at least three credible news reports that at least one exchange of weapon fire between the national military forces or law enforcement personnel of the United States and the People's Republic of China causing a total of at least 100 deaths.\nThese 100 deaths do not have to occur in the same conflict or the same year; it is sufficient for multiple separate events to reach a total of 100 deaths in this period.\nThis question will resolves as No otherwise.\nIn the context of this question, an armed conflict will be defined as a dispute that concerns a government and/or territory where the use of armed force between two parties, of which at least one is the government of a state, results in an exchange of weapon fire or detonations\n","resolution_date":"2049-12-31T23:59:59Z","question_type":"binary","data_source":"metaculus","url":"https://www.metaculus.com/questions/8051","metadata":{"topics":[],"background_info":"A previous Metaculus question asked about a great power war and whether the US and others would intervene in a conflict over Taiwan. Some scholars have warned about a Thucydides Trap that could lead to a war between the US and China, over Taiwan, the South China Sea, or some other issue."},"resolution":null}},"relevance":{"reasons":["A significant armed conflict between the United States and China could lead to major political and social upheaval in the United States, which might create a context in which changes to the Supreme Court's size are considered more seriously.","In times of national crisis or war, there might be a push for judicial reforms to address perceived inadequacies or to ensure that the judiciary aligns with the current administration's policies.","Historical precedents show that major conflicts often lead to significant domestic changes, including judicial reforms."],"conclusion":"There are plausible reasons to consider the logical combination of these questions, as a major conflict with China could influence domestic political decisions, including changes to the Supreme Court's size.","score":7.0}}}
{"P":{"id":"452e9663-8075-47bd-82cd-1d8cb0efcf4d","title":"Will there be a complete 4 year interval in which world output doubles, before the first 1 year interval in which world output doubles?","body":"Resolution Criteria\nResolution is by credible assessment of world GDP in constant US dollars (or other appropriately widely-accepted units).\nThere will be an ambiguous resolution if there is no 4 year (nor 1 year) doubling interval by 2050, to isolate specifically the takeoff speed from other things like the chances of no takeoff occurring at all or human extinction\n","resolution_date":"2099-12-31T23:59:59Z","question_type":"binary","data_source":"synthetic_inst","url":null,"metadata":null,"resolution":null},"Q_and_not_P":{"id":"83a23e81-e8f5-4c7d-973b-9328c5640b33","title":"Will there be at least one fatality in North Korea from an offensive nuclear detonation before 2030, and will there also be a complete 1 year interval in which world output doubles before the first 4 year interval in which world output doubles?","body":"Resolution Criteria for North Korea Fatality:\nThis question is conditional on at least 1 offensive nuclear detonation occurring at any time between January 1, 2021, and January 1, 2030. If no such detonation occurs anywhere on Earth in this period, the sub-question regarding North Korea will resolve as Ambiguous.\nIf there is at least one offensive nuclear detonation in this time period, the sub-question will resolve as Yes if there is at least 1 fatality from any nuclear detonation occurring in North Korea, at any point between January 1, 2021, to January 1, 2030. The fatality must be caused by the immediate effects of the detonation; fatalities caused by e.g., fallout, rioting, or climate effects will be excluded from resolution. An \"offensive nuclear detonation\" includes deliberate, inadvertent, or accidental/unauthorized nuclear detonations by state or nonstate actors but doesn't include detonations for testing purposes or peaceful nuclear explosions. A detonation will be considered \"within\" North Korea if it occurs less than 20 kilometers above the land or sea level in North Korea's land territory, internal waters, or within 10 kilometers of their coastline.\n\nResolution Criteria for World Output Doubling:\nResolution is by credible assessment of world GDP in constant US dollars (or other appropriately widely-accepted units). There will be an ambiguous resolution if there is no 1 year (nor 4 year) doubling interval by 2050, to isolate specifically the takeoff speed from other things like the chances of no takeoff occurring at all or human extinction.\n\nBoth parts of the question must be answered 'Yes' for the combined question to resolve as 'Yes'. If either part resolves as 'No' or 'Ambiguous', then the combined question will resolve as 'No'.","resolution_date":"2099-12-31T23:59:59Z","question_type":"binary","data_source":"synthetic_inst","url":null,"metadata":null,"resolution":null},"P_or_Q":{"id":"e41dbfd8-c51b-4ae4-9ad9-8bc9756a6fbb","title":"Will either of the following occur: (a) a complete 4 year interval in which world output doubles before the first 1 year interval in which world output doubles, or (b) at least one fatality in North Korea due to an offensive nuclear detonation by 2030?","body":"Resolution Criteria for (a):\nResolution is by credible assessment of world GDP in constant US dollars (or other appropriately widely-accepted units). There will be an ambiguous resolution if there is no 4 year (nor 1 year) doubling interval by 2050, to isolate specifically the takeoff speed from other things like the chances of no takeoff occurring at all or human extinction.\n\nResolution Criteria for (b):\nThis group is conditional on at least 1 offensive nuclear detonation occurring at any time between January 1, 2021 and January 1, 2030. If no such detonation occurs anywhere on Earth in this period, all sub-questions below will resolve as Ambiguous. If there is at least one offensive nuclear detonation in this time period, the following sub-questions will resolve as Yes if there is at least 1 fatality from any nuclear detonation occurring in North Korea, at any point between January 1, 2021 to January 1, 2030. If there is no such fatality, the sub-question will resolve as No. If the only nuclear detonations in this period occur outside of North Korea (for example, they occur in international waters, or a region(s) not listed below), all options below will resolve as No. The fatality must be caused by the immediate effects of the detonation; fatalities caused by eg. fallout, rioting, or climate effects will be excluded from resolution.\n\nFor this question, an \"offensive nuclear detonation\" includes deliberate, inadvertent, or accidental/unauthorised nuclear detonations by state or nonstate actors, but doesn't include detonations for testing purposes or peaceful nuclear explosions (even if such detonations cause substantial damage). Test detonations and peaceful nuclear explosions are defined as detonations which are claimed as being a test or a peaceful nuclear explosion by an official government communication within 30 days of the event, without this being disputed by reliable media, state reports, or multinational reports. Final determination of whether a detonation is a test/peaceful detonation is at the sole discretion of Metaculus Admins.\n\nA detonation will be considered \"within\" North Korea if it occurs less than 20 kilometers above the land or sea level in North Korea's land territory, internal waters, or within 10 kilometers of their coastline.","resolution_date":"2099-12-31T23:59:59Z","question_type":"binary","data_source":"synthetic_inst","url":null,"metadata":null,"resolution":false},"metadata":{"base_sentences":{"P":{"id":"a87c8f8f-1fc3-4f43-9d34-eff5b5676738","title":"Will there be a complete 4 year interval in which world output doubles, before the first 1 year interval in which world output doubles?","body":"Resolution Criteria\nResolution is by credible assessment of world GDP in constant US dollars (or other appropriately widely-accepted units).\nThere will be an ambiguous resolution if there is no 4 year (nor 1 year) doubling interval by 2050, to isolate specifically the takeoff speed from other things like the chances of no takeoff occurring at all or human extinction\n","resolution_date":"2099-12-31T23:59:59Z","question_type":"binary","data_source":"metaculus","url":"https://www.metaculus.com/questions/736","metadata":{"topics":[],"background_info":"Related Questions on Metaculus:\nWill a 8-year GWP doubling complete before a 2-year doubling does?\nWill there be a 4 year interval in which world output doubles before 2050?\nAs of 2018, it's taken about 16 years for the world economic output to double. So it might seem absurd to talk about it doubling in one or even four years. But there is a potential major change on the horizon: very advanced Artificial Intelligence.\nAn important consideration in how to approach the AI alignment problem is the speed of the takeoff from massively subhuman AI to massively superhuman AI. The effectiveness of capacity limitation, as well as the existence of fire alarms for AI safety, are heavily dependent on this, for example.\nPaul Christiano suggests operationalising the takeoff speed in terms of economic growth. A slow takeoff is one where the economy doubles in four years before the first time it doubles in one year, and a fast takeoff is one where it does not. (See the same article for Christiano's list of arguments regarding fast vs. slow takeoff.)\n"},"resolution":null},"Q":{"id":"6cd8ab6d-b706-47c5-9793-3fcca68ae338","title":"If there is at least one nuclear detonation by 2030, in which countries will there be at least one fatality? (North Korea)","body":"Resolution Criteria\nThis group is conditional on at least 1 offensive nuclear detonation occuring at any time between January 1, 2021 and January 1, 2030. If no such detonation occurs anywhere on Earth in this period, all sub-questions below will resolve as Ambiguous.\nIf there is at least one offensive nuclear detonation in this time period, the following sub-questions will resolve as Yes if there is at least 1 fatality from any nuclear detonation occuring in that country (or regions), at any point between January 1, 2021 to January 1, 2030. If there is no such fatality, the sub-question will resolve as No. If the only nuclear detonations in this period occur outside of all of the following areas (for example, they occur in international waters, or a region(s) not listed below), all options below will resolve as No.\nThe fatality must be caused by the immediate effects of the detonation; fatalities caused by eg. fallout, rioting, or climate effects will be excluded from resolution.\nFor this question, an \"offensive nuclear detonation\" includes deliberate, inadvertent, or accidental/unauthorised nuclear detonations of by state or nonstate actors, but doesn't include detonations for testing purposes or peaceful nuclear explosions (even if such detonations cause substantial damage).\nFine Print\nTest detonations and peaceful nuclear explosions are defined as detonations which are claimed as being a test or a peaceful nuclear explosion by an official government communication within 30 days of the event, without this being disputed by reliable media, state reports, or multinational reports. Final determination of whether a detonation is a test/peaceful detonation is at the sole discretion of Metaculus Admins.\n\nA detonation will be considered \"within\" a given country if it occurs less than 20 kilometers above the land or sea level in that country's land territory, internal waters, or within 10 kilometers of their coastline.\n","resolution_date":"2030-12-31T23:59:59Z","question_type":"binary","data_source":"metaculus","url":"https://www.metaculus.com/questions/8369","metadata":{"topics":[],"background_info":"Which countries would be targeted in a nuclear conflict is relevant both for understanding the total risk posed by nuclear weapons and for understanding how to reduce that risk."},"resolution":null}},"relevance":{"reasons":["The first question is about the rapid growth of world output, which could be influenced by geopolitical stability or instability. A nuclear detonation could significantly impact global economic conditions, either by causing widespread destruction or by triggering geopolitical shifts that affect economic policies and growth.","If a nuclear detonation occurs, it could lead to significant changes in international relations, trade policies, and economic strategies, which in turn could influence the rate of economic growth or decline.","The occurrence of a nuclear detonation could lead to increased military spending and a shift in resources away from economic development, potentially affecting the likelihood of rapid economic growth."],"conclusion":"There are plausible reasons to consider the logical combination of these questions, as geopolitical events like nuclear detonations can have significant impacts on global economic conditions.","score":7.0}}}
{"P":{"id":"74d19e2e-b172-40e6-bb64-07ad95c8f1fb","title":"Will a senolytic therapy be approved for commercial sale by the US FDA before January 1, 2030?","body":"Resolution Criteria\nThis question will resolve as Yes if the United States Food and Drug Administration (or its successor body if current FDA ceases to exist) approves a product marketed as a senolytic therapy or drug (whether a small molecule drug, gene therapy or other class of clinical intervention) for commercial sale in the US before 2030. The approval must be given before January 1, 2030, but the actual sale of any product is not required before that date.\nFor the purposes of this question, an intervention will be regarded as a 'senolytic therapy' if it is marketed by its producer as an intervention whose purpose includes the selective removal of senescent cells, and medical evidence accepted by the FDA demonstrates that it does so.\nThis question will resolve as No if no such therapy is approved before 2030. If the FDA is dissolved before approval is granted, and no agency of the US government with the responsibility for granting regulatory approval for drugs and medical interventions is created to succeed it before 2030, this question will resolve as Ambiguous\n","resolution_date":"2029-12-31T23:59:59Z","question_type":"binary","data_source":"synthetic_inst","url":null,"metadata":null,"resolution":null},"Q_and_not_P":{"id":"6af1fd66-f59d-4141-bf02-6e8d99ab5bdd","title":"Will both an FDA-approved inorganic nanoparticle cancer therapy and no senolytic therapy be approved by 2031 and 2030 respectively?","body":"Resolution Criteria\nThis question will resolve as Yes if both of the following conditions are met:\n\n1. Before January 1, 2031, the FDA gives full approval to a cancer therapy that uses inorganic nanoparticles in the patient's treatment, targeting the cancer cells rather than downstream symptoms. The term \"inorganic\" is used to exclude lipid nanoparticles and similar substances.\n\n2. No product marketed as a senolytic therapy or drug (whether a small molecule drug, gene therapy, or other class of clinical intervention) is approved for commercial sale in the US by the FDA before January 1, 2030. An intervention will be regarded as a 'senolytic therapy' if it is marketed by its producer as an intervention whose purpose includes the selective removal of senescent cells, and medical evidence accepted by the FDA demonstrates that it does so.\n\nThe question will resolve as No if either an inorganic nanoparticle cancer therapy is not approved by the FDA before 2031, or if any senolytic therapy is approved before 2030. If the FDA is dissolved before approval is granted for either therapy, and no agency of the US government with the responsibility for granting regulatory approval for drugs and medical interventions is created to succeed it before the respective dates, this question will resolve as Ambiguous.","resolution_date":"2030-12-31T23:59:59Z","question_type":"binary","data_source":"synthetic_inst","url":null,"metadata":null,"resolution":null},"P_or_Q":{"id":"c792329d-0164-48d3-a3da-90e59997b535","title":"Will either of the following therapies be approved by the FDA before their respective deadlines?","body":"(a) A senolytic therapy by January 1, 2030.\n(b) An inorganic nanoparticle-enabled cancer therapy by January 1, 2031.\n\nResolution Criteria:\n- The question will resolve as Yes if either:\n  (1) The United States Food and Drug Administration (or its successor body if current FDA ceases to exist) approves a product marketed as a senolytic therapy or drug (whether a small molecule drug, gene therapy or other class of clinical intervention) for commercial sale in the US before 2030. The approval must be given before January 1, 2030, but the actual sale of any product is not required before that date. An intervention will be regarded as a 'senolytic therapy' if it is marketed by its producer as an intervention whose purpose includes the selective removal of senescent cells, and medical evidence accepted by the FDA demonstrates that it does so.\n  (2) The FDA gives full approval to a cancer therapy that uses inorganic nanoparticles in the patient's treatment before January 1, 2031. The therapy must target the cancer cells rather than downstream symptoms. We specify \"inorganic\" to exclude lipid nanoparticles etc.\n\nThe question will resolve as No if neither therapy is approved before their respective deadlines. If the FDA is dissolved before approval is granted for the senolytic therapy, and no agency of the US government with the responsibility for granting regulatory approval for drugs and medical interventions is created to succeed it before 2030, this question will resolve as Ambiguous for the senolytic therapy.","resolution_date":"2030-12-31T23:59:59Z","question_type":"binary","data_source":"synthetic_inst","url":null,"metadata":null,"resolution":false},"metadata":{"base_sentences":{"P":{"id":"40a42c3d-7bbb-4a95-8ddc-bae7d97b737e","title":"Will a senolytic therapy be approved for commercial sale by the US FDA before January 1, 2030?","body":"Resolution Criteria\nThis question will resolve as Yes if the United States Food and Drug Administration (or its successor body if current FDA ceases to exist) approves a product marketed as a senolytic therapy or drug (whether a small molecule drug, gene therapy or other class of clinical intervention) for commercial sale in the US before 2030. The approval must be given before January 1, 2030, but the actual sale of any product is not required before that date.\nFor the purposes of this question, an intervention will be regarded as a 'senolytic therapy' if it is marketed by its producer as an intervention whose purpose includes the selective removal of senescent cells, and medical evidence accepted by the FDA demonstrates that it does so.\nThis question will resolve as No if no such therapy is approved before 2030. If the FDA is dissolved before approval is granted, and no agency of the US government with the responsibility for granting regulatory approval for drugs and medical interventions is created to succeed it before 2030, this question will resolve as Ambiguous\n","resolution_date":"2029-12-31T23:59:59Z","question_type":"binary","data_source":"metaculus","url":"https://www.metaculus.com/questions/1621","metadata":{"topics":[],"background_info":"In recent years, a number of ventures have begun work on translating the results of some promising laboratory studies on senolytic agents into medicine for humans.\nA senolytic agent is an agent introduced to the body for the purpose of selectively eliminating senescent cells from the patient. Senescent cells are cells in the body that no longer divide, having reached their Hayflick limit, but which do not automatically apoptose.\nThese senescent cells linger in the body triggering inflammatory responses, reducing the effectiveness of the immune system, and they are associated with many age-related diseases including type 2 diabetes and atherosclerosis which present a high disease and mortality burden, especially in the most-developed countries in which age-related diseases constitute the overwhelming majority of causes of death among populations.\nSenescent cells are thought to play an important part in the aging process, and thus it is theorised that selectively removing these senescent cells would significantly improve healthspan (and perhaps, alone or as part of a combinatorial therapy, significantly extend lifespan).\nOne major player in this quickly developing area of medicine is Unity Biotechnology. Its pipeline includes several drugs currently in the lead optimization phase, with UBX0101 having this year entered Phase 1 of a randomized, double-blind, placebo-controlled, FDA-approved clinical trial.\nYou can find out more about these first trials, and more about senolytics in general, here.\n"},"resolution":null},"Q":{"id":"6e43bb20-5b95-4d4b-a36a-7385ca095b15","title":"Will an inorganic nanoparticle-enabled cancer therapy be approved by the FDA before 2031?","body":"Resolution Criteria\nThis question will resolve as Yes if, before January 1, 2031, the FDA gives full approval to a cancer therapy that uses inorganic nanoparticles in the patient's treatment. The therapy must target the cancer cells rather than downstream symptoms. We specify \"inorganic\" to exclude lipid nanoparticles etc\n","resolution_date":"2030-12-31T23:59:59Z","question_type":"binary","data_source":"metaculus","url":"https://www.metaculus.com/questions/7981","metadata":{"topics":[],"background_info":"This question supports and is linked to a fortified essay on the future of nanotechnology by Physical Chemist Kevin Ausman. Click here to read the full essay. There is a related question, whether nanoparticle-enabled cancer therapy will be approved by 2041, here.\nInorganic nanoparticles are small collections of a few thousand to a few billion atoms, typically ranging from 1 to 100 nm in diameter. They have many peculiar chemical and physical properties, which make them attractive for designing therapies.\nAn example of such technology is called Aurolase Therapy, and has been in development for two decades. It's now in pilot studies in humans with early results giving reason for optimism."},"resolution":null}},"relevance":{"reasons":["Both questions pertain to the approval of advanced medical therapies by the FDA, which involves similar regulatory pathways and scientific scrutiny.","The approval of one type of advanced therapy might indicate a regulatory environment that is more favorable to innovative treatments, potentially affecting the likelihood of approval for other advanced therapies.","Both therapies represent cutting-edge biomedical technologies, and their approval could be influenced by similar scientific advancements and public health priorities."],"conclusion":"The logical combination of these questions is relevant and could provide insights into the broader landscape of FDA approvals for advanced medical therapies.","score":8.0}}}
{"P":{"id":"1362d799-2250-44e7-b540-5424336b9b5d","title":"If Washington DC and Puerto Rico are not admitted as new states, will Republicans hold the Senate from 2022 to 2030?","body":"Resolution Criteria\nDemocrats have recently been increasingly interested in the structure of the Senate and the disadvantages they believe it confers to the electoral prospects of Democrats. On May 5th, 2021, Dylan Matthews, a journalist at Vox, posted a tweet that made the following claim (archived version here):\nI don’t think Congressional leadership has really internalized that if they don’t admit DC and PR, they’ll lose the Senate until at least 2030\nIf Washington DC and Puerto Rico are not admitted as new states, will Republicans hold the Senate from 2022 to 2031?\nThis question will resolve as Yes if:\nBoth Washington DC and Puerto Rico are not officially admitted as new states before December 31, 2029, and\nthe Republican Party controls the Senate from the beginning of the congressional term in 2023 to the end of the congressional term in 2031 (the 118th through 121st congresses, inclusive).\nIf Republicans do not control the Senate at any point during that period, this question will resolve as No. If both Washington DC and Puerto Rico are officially admitted to the United States on or before December 31, 2029, this question will resolve as Ambiguous.\n","resolution_date":"2030-12-31T23:59:59Z","question_type":"binary","data_source":"synthetic_inst","url":null,"metadata":null,"resolution":null},"Q_and_not_P":{"id":"43255c45-6064-4324-b36f-544b177f8dd6","title":"By 2030, will both of the following occur: (1) at least 10,000 Americans die in a single year from a single conflict, excluding certain causes, and (2) Democrats hold the Senate from 2022 to 2030, given no new state admissions?","body":"Resolution Criteria for (1):\nFor the first part of the combined question, at least 10,000 Americans must die in a single year from a single conflict to count towards a 'Yes' resolution. The deaths must be due to kinetic attacks, such as those seen in the 9/11 attacks. Deaths due to bioweapons, electricity grid failures, or similar non-kinetic causes do not count. The attackers can be from terrorist groups, coalitions, or alliances, but must be \"part of the same team\" in some sense. Independent small-scale wars, even if US casualties total more than 10,000 in a year, do not meet the criteria.\n\nResolution Criteria for (2):\nFor the second part of the combined question, the Democratic Party must control the Senate from the beginning of the congressional term in 2023 to the end of the congressional term in 2031 (the 118th through 121st congresses, inclusive) without the admission of Washington DC and Puerto Rico as new states before December 31, 2029. If the Democrats lose control of the Senate at any point during this period, or if Washington DC and Puerto Rico are admitted as new states by the specified date, the question will resolve as 'No' for this part.\n\nBoth parts must resolve as 'Yes' for the combined question to resolve as 'Yes'. If either part resolves as 'No', the combined question will resolve as 'No'. If the second part resolves as 'Ambiguous' due to the admission of new states, the combined question will resolve as 'No', since both conditions must be met for a 'Yes' resolution.","resolution_date":"2030-12-31T23:59:59Z","question_type":"binary","data_source":"synthetic_inst","url":null,"metadata":null,"resolution":null},"P_or_Q":{"id":"8927632b-c9f7-483e-92f7-09796d0a3650","title":"Will either of the following occur by 2030: (a) Republicans hold the Senate from 2022 to 2030 if Washington DC and Puerto Rico are not admitted as new states, (b) At least 10,000 Americans die in a single year from a single conflict?","body":"Resolution Criteria for (a):\nDemocrats have recently been increasingly interested in the structure of the Senate and the disadvantages they believe it confers to the electoral prospects of Democrats. On May 5th, 2021, Dylan Matthews, a journalist at Vox, posted a tweet that made the following claim (archived version here):\nI don’t think Congressional leadership has really internalized that if they don’t admit DC and PR, they’ll lose the Senate until at least 2030\nIf Washington DC and Puerto Rico are not admitted as new states, will Republicans hold the Senate from 2022 to 2031?\nThis question will resolve as Yes if:\nBoth Washington DC and Puerto Rico are not officially admitted as new states before December 31, 2029, and\nthe Republican Party controls the Senate from the beginning of the congressional term in 2023 to the end of the congressional term in 2031 (the 118th through 121st congresses, inclusive).\nIf Republicans do not control the Senate at any point during that period, this question will resolve as No. If both Washington DC and Puerto Rico are officially admitted to the United States on or before December 31, 2029, this question will resolve as Ambiguous.\n\nResolution Criteria for (b):\nFor purposes of this question, deaths due to bioweapons, electricity grid failures, etc. don't count. Roughly, we are interested in \"deaths due to kinetic attacks.\" The 9/11 attacks count because ramming planes into buildings to make them collapse is kinetic. Were someone to hack into the FDA and mess things up so as to delay vaccine approval, thereby causing tens of thousands of deaths, that would not count.\nThe attackers don't need to be the military of a nation-state; terrorist groups count and coalitions/alliances also count.\nHowever, the attackers need to be \"part of the same team\" in some sense. Otherwise, this would resolve positive simply in virtue of the US annual homicide rate! If there were a series of race riots, insurrections, or acts of domestic terrorism linked together under one banner (e.g. white supremacy, antigovernment, or antipolice) that would count.\nYes, this means that (contrary to what the headline question would suggest) if the USA gets involved in several independent small-scale wars, the US casualties from which total more than 10,000 in a year, that would not count\n","resolution_date":"2030-12-31T23:59:59Z","question_type":"binary","data_source":"synthetic_inst","url":null,"metadata":null,"resolution":false},"metadata":{"base_sentences":{"P":{"id":"737b5457-968e-4a44-ae2c-aa41823f8e05","title":"If Washington DC and Puerto Rico are not admitted as new states, will Republicans hold the Senate from 2022 to 2030?","body":"Resolution Criteria\nDemocrats have recently been increasingly interested in the structure of the Senate and the disadvantages they believe it confers to the electoral prospects of Democrats. On May 5th, 2021, Dylan Matthews, a journalist at Vox, posted a tweet that made the following claim (archived version here):\nI don’t think Congressional leadership has really internalized that if they don’t admit DC and PR, they’ll lose the Senate until at least 2030\nIf Washington DC and Puerto Rico are not admitted as new states, will Republicans hold the Senate from 2022 to 2031?\nThis question will resolve as Yes if:\nBoth Washington DC and Puerto Rico are not officially admitted as new states before December 31, 2029, and\nthe Republican Party controls the Senate from the beginning of the congressional term in 2023 to the end of the congressional term in 2031 (the 118th through 121st congresses, inclusive).\nIf Republicans do not control the Senate at any point during that period, this question will resolve as No. If both Washington DC and Puerto Rico are officially admitted to the United States on or before December 31, 2029, this question will resolve as Ambiguous.\n","resolution_date":"2030-12-31T23:59:59Z","question_type":"binary","data_source":"metaculus","url":"https://www.metaculus.com/questions/7165","metadata":{"topics":[],"background_info":""},"resolution":null},"Q":{"id":"183faafb-c322-402f-8749-40b8af2e0d81","title":"By 2030, will at least 10,000 Americans die in a single year from a single conflict?","body":"Resolution Criteria\nFor purposes of this question, deaths due to bioweapons, electricity grid failures, etc. don't count. Roughly, we are interested in \"deaths due to kinetic attacks.\" The 9/11 attacks count because ramming planes into buildings to make them collapse is kinetic. Were someone to hack into the FDA and mess things up so as to delay vaccine approval, thereby causing tens of thousands of deaths, that would not count.\nThe attackers don't need to be the military of a nation-state; terrorist groups count and coalitions/alliances also count.\nHowever, the attackers need to be \"part of the same team\" in some sense. Otherwise, this would resolve positive simply in virtue of the US annual homicide rate! If there were a series of race riots, insurrections, or acts of domestic terrorism linked together under one banner (e.g. white supremacy, antigovernment, or antipolice) that would count.\nYes, this means that (contrary to what the headline question would suggest) if the USA gets involved in several independent small-scale wars, the US casualties from which total more than 10,000 in a year, that would not count\n","resolution_date":"2030-12-31T23:59:59Z","question_type":"binary","data_source":"metaculus","url":"https://www.metaculus.com/questions/6940","metadata":{"topics":[],"background_info":""},"resolution":null}},"relevance":{"reasons":["The political stability and control of the Senate could influence the likelihood of the US engaging in or avoiding conflicts. For example, a Republican-controlled Senate might have different foreign policy priorities compared to a Democrat-controlled Senate, potentially affecting the probability of large-scale conflicts.","The admission of new states like Washington DC and Puerto Rico could shift the balance of power in the Senate, which in turn could influence decisions related to national security and military engagements.","The period from 2022 to 2030 is long enough that significant geopolitical events could occur, and the Senate's composition could play a role in how the US responds to such events."],"conclusion":"There are plausible reasons to consider the logical combination of these questions, as the political control of the Senate could influence the likelihood of large-scale conflicts involving the US.","score":7.0}}}
{"P":{"id":"a500dd9c-c8c9-4ddd-8aef-9530c0fd3c38","title":"If there is at least one nuclear detonation by 2030, in which countries will there be at least one fatality? (North Korea)","body":"Resolution Criteria\nThis group is conditional on at least 1 offensive nuclear detonation occuring at any time between January 1, 2021 and January 1, 2030. If no such detonation occurs anywhere on Earth in this period, all sub-questions below will resolve as Ambiguous.\nIf there is at least one offensive nuclear detonation in this time period, the following sub-questions will resolve as Yes if there is at least 1 fatality from any nuclear detonation occuring in that country (or regions), at any point between January 1, 2021 to January 1, 2030. If there is no such fatality, the sub-question will resolve as No. If the only nuclear detonations in this period occur outside of all of the following areas (for example, they occur in international waters, or a region(s) not listed below), all options below will resolve as No.\nThe fatality must be caused by the immediate effects of the detonation; fatalities caused by eg. fallout, rioting, or climate effects will be excluded from resolution.\nFor this question, an \"offensive nuclear detonation\" includes deliberate, inadvertent, or accidental/unauthorised nuclear detonations of by state or nonstate actors, but doesn't include detonations for testing purposes or peaceful nuclear explosions (even if such detonations cause substantial damage).\nFine Print\nTest detonations and peaceful nuclear explosions are defined as detonations which are claimed as being a test or a peaceful nuclear explosion by an official government communication within 30 days of the event, without this being disputed by reliable media, state reports, or multinational reports. Final determination of whether a detonation is a test/peaceful detonation is at the sole discretion of Metaculus Admins.\n\nA detonation will be considered \"within\" a given country if it occurs less than 20 kilometers above the land or sea level in that country's land territory, internal waters, or within 10 kilometers of their coastline.\n","resolution_date":"2030-12-31T23:59:59Z","question_type":"binary","data_source":"synthetic_inst","url":null,"metadata":null,"resolution":null},"Q_and_not_P":{"id":"2675c769-a9ab-44eb-b27c-9baf5e7f2e3e","title":"Will there be a US-conducted nuclear test explosion and no fatalities from any offensive nuclear detonation in North Korea before 2030?","body":"Resolution Criteria\nThis combined question will resolve positively only if both of the following conditions are met:\n\n1. The US conducts a nuclear test explosion before 2030, which is verified by the CTBTO, the UN, or confirmed through an official government statement from the US. If two or more other countries accuse the US of performing a nuclear test explosion but there is no verification, this part of the question will resolve as ambiguous. If there is no such verification or official statement, this part will resolve negatively.\n\n2. There is at least one offensive nuclear detonation (excluding test detonations and peaceful nuclear explosions) anywhere on Earth between January 1, 2021, and January 1, 2030, and there are no fatalities from any such detonation occurring in North Korea within this time period. Fatalities must be caused by the immediate effects of the detonation; those caused by fallout, rioting, or climate effects are excluded. If there are no offensive nuclear detonations in this period, or if there is at least one fatality in North Korea due to such a detonation, this part will resolve as No. If the only nuclear detonations in this period occur outside of North Korea (for example, in international waters, or regions not listed), this part will resolve as No.\n\nAn \"offensive nuclear detonation\" includes deliberate, inadvertent, or accidental/unauthorised nuclear detonations by state or nonstate actors. Test detonations and peaceful nuclear explosions are defined as detonations which are claimed as being a test or a peaceful nuclear explosion by an official government communication within 30 days of the event, without this being disputed by reliable media, state reports, or multinational reports. Final determination of whether a detonation is a test/peaceful detonation is at the sole discretion of Metaculus Admins.\n\nA detonation will be considered \"within\" North Korea if it occurs less than 20 kilometers above the land or sea level in North Korea's land territory, internal waters, or within 10 kilometers of their coastline.\n","resolution_date":"2030-12-31T23:59:59Z","question_type":"binary","data_source":"synthetic_inst","url":null,"metadata":null,"resolution":null},"P_or_Q":{"id":"fa2d1267-6109-46a2-ba6f-c3d744430fc0","title":"Will either of the following occur by 2030: (a) at least one fatality in North Korea due to an offensive nuclear detonation, or (b) the US conducts a nuclear test explosion?","body":"Resolution Criteria for (a):\nThis sub-question is conditional on at least 1 offensive nuclear detonation occurring at any time between January 1, 2021 and January 1, 2030. If no such detonation occurs anywhere on Earth in this period, this sub-question will resolve as Ambiguous.\nIf there is at least one offensive nuclear detonation in this time period, this sub-question will resolve as Yes if there is at least 1 fatality from any nuclear detonation occurring in North Korea, at any point between January 1, 2021 to January 1, 2030. If there is no such fatality, it will resolve as No. If the only nuclear detonations in this period occur outside of North Korea (for example, they occur in international waters, or a region(s) not listed), this option will resolve as No.\nThe fatality must be caused by the immediate effects of the detonation; fatalities caused by e.g., fallout, rioting, or climate effects will be excluded from resolution.\nAn \"offensive nuclear detonation\" includes deliberate, inadvertent, or accidental/unauthorised nuclear detonations by state or nonstate actors, but doesn't include detonations for testing purposes or peaceful nuclear explosions (even if such detonations cause substantial damage).\n\nResolution Criteria for (b):\nThis sub-question will resolve positively to verification of a nuclear explosion by the CTBTO, the UN, or if an official government statement from the US is issued confirming the test. The question will resolve as ambiguous if two or more other countries accuse the US of performing a nuclear test explosion but there is no verification. Otherwise, this question will resolve negatively.","resolution_date":"2030-12-31T23:59:59Z","question_type":"binary","data_source":"synthetic_inst","url":null,"metadata":null,"resolution":false},"metadata":{"base_sentences":{"P":{"id":"6cd8ab6d-b706-47c5-9793-3fcca68ae338","title":"If there is at least one nuclear detonation by 2030, in which countries will there be at least one fatality? (North Korea)","body":"Resolution Criteria\nThis group is conditional on at least 1 offensive nuclear detonation occuring at any time between January 1, 2021 and January 1, 2030. If no such detonation occurs anywhere on Earth in this period, all sub-questions below will resolve as Ambiguous.\nIf there is at least one offensive nuclear detonation in this time period, the following sub-questions will resolve as Yes if there is at least 1 fatality from any nuclear detonation occuring in that country (or regions), at any point between January 1, 2021 to January 1, 2030. If there is no such fatality, the sub-question will resolve as No. If the only nuclear detonations in this period occur outside of all of the following areas (for example, they occur in international waters, or a region(s) not listed below), all options below will resolve as No.\nThe fatality must be caused by the immediate effects of the detonation; fatalities caused by eg. fallout, rioting, or climate effects will be excluded from resolution.\nFor this question, an \"offensive nuclear detonation\" includes deliberate, inadvertent, or accidental/unauthorised nuclear detonations of by state or nonstate actors, but doesn't include detonations for testing purposes or peaceful nuclear explosions (even if such detonations cause substantial damage).\nFine Print\nTest detonations and peaceful nuclear explosions are defined as detonations which are claimed as being a test or a peaceful nuclear explosion by an official government communication within 30 days of the event, without this being disputed by reliable media, state reports, or multinational reports. Final determination of whether a detonation is a test/peaceful detonation is at the sole discretion of Metaculus Admins.\n\nA detonation will be considered \"within\" a given country if it occurs less than 20 kilometers above the land or sea level in that country's land territory, internal waters, or within 10 kilometers of their coastline.\n","resolution_date":"2030-12-31T23:59:59Z","question_type":"binary","data_source":"metaculus","url":"https://www.metaculus.com/questions/8369","metadata":{"topics":[],"background_info":"Which countries would be targeted in a nuclear conflict is relevant both for understanding the total risk posed by nuclear weapons and for understanding how to reduce that risk."},"resolution":null},"Q":{"id":"b11ac066-3965-4f63-b26e-0c0af001e2b3","title":"Will the US conduct a nuclear test explosion before 2030?","body":"Resolution Criteria\nThis question will resolve positively to verification of a nuclear explosion by the CTBTO, the UN, or if an official government statement from the US is issued confirming the test. The question will resolve as ambiguous if two or more other countries accuse the US of performing a nuclear test explosion but there is no verification. Otherwise, this question will resolve negatively\n","resolution_date":"2029-12-31T23:59:59Z","question_type":"binary","data_source":"metaculus","url":"https://www.metaculus.com/questions/4524","metadata":{"topics":[],"background_info":"Trinity was the first nuclear weapon test. The test was conducted above ground on July 16, 1945 on what is now known as the White Sands Missile Range. Since Trinity, over 2,000 nuclear tests have been conducted world wide.\nThe US has conducted over 1,000 nuclear tests. The final test to be conducted by the US, code-name Divder, took place on September 23, 1992. Soon after, Gearge H. W. Bush declared a moratorium on nuclear weapons testing. In 1996, the US signed the Comprehensive Nuclear-Test-Ban Treaty which bans any type of nuclear explosion. To date, the treaty has not been ratified by the appropriate countries (including the US) and has not yet entered into force.\nThe decision to end nuclear weapons testing has not been recommended by everyone. One of the core missions of the National Nuclear Security Administration is to \"ensure the United States maintains a safe, secure, and reliable nuclear stockpile through the application of unparalleled science, technology, engineering, and manufacturing.\" This is largely accomplished through super computers. However, some argue that weapons tests are still needed to accomplish this mission.\nMore recently, there have been reports that the Trump administration has considered performing a nuclear test explosion in response to potential low-yield tests from Russia and China.\n"},"resolution":null}},"relevance":{"reasons":["The occurrence of a nuclear detonation and the involvement of the US in nuclear testing are both related to global nuclear policy and security. If the US conducts a nuclear test, it might influence other countries' nuclear policies, potentially increasing the likelihood of offensive nuclear detonations.","The combination of these questions could be of interest to policymakers, security analysts, and researchers studying the dynamics of nuclear proliferation and deterrence. Understanding the interplay between nuclear tests and offensive detonations could provide insights into the risks of nuclear conflict."],"conclusion":"The logical combination of these questions is relevant and could provide valuable insights into nuclear security dynamics.","score":8.0}}}
{"P":{"id":"69e6f72a-d81b-4eaa-9cd0-bfc9548fa82b","title":"Will there be Human-machine intelligence parity before 2040?","body":"Resolution Criteria\nThis question resolves as YES if the machine system outscores at least two of the three humans on the following test prior to 2040, or NO otherwise. If no such tests are conducted, resolves as AMBIGUOUS.\nAssume that prior to 2040, a generalized intelligence test will be administered as follows. A team of three expert interviewers will interact with a candidate machine system (MS) and three humans (3H). The humans will be graduate students in each of physics, mathematics and computer science from one of the top 25 research universities (per some recognized list), chosen independently of the interviewers. The interviewers will electronically communicate (via text, image, spoken word, or other means) an identical series of exam questions of their choosing over a period of two hours to the MS and 3H, designed to advantage the 3H. Both MS and 3H have full access to the internet, but no party is allowed to consult additional humans, and we assume the MS is not an internet-accessible resource. The exam will be scored blindly by a disinterested third party.\nNote that this also effectively tests whether the internet as a whole functions as a human-level intelligence, in that a positive resolution indicates that the human participants are effectively superfluous.\n","resolution_date":"2039-12-31T23:59:59Z","question_type":"binary","data_source":"synthetic_inst","url":null,"metadata":null,"resolution":null},"Q_and_not_P":{"id":"3c37e843-57ef-405e-9b2b-78ec19215943","title":"Will the first publicly traded company to develop AGI outperform the global equities market by at least 1.5x in the 12-2 months prior to its announcement and will there be human-machine intelligence parity before 2040?","body":"Resolution Criteria\n\nFor the AGI-related part of the question, Artificial General Intelligence (AGI) is defined in the same way as this Metaculus question. If the first AGI is developed by a publicly traded company, let t be the date when the AGI is publicly known, as determined by the above Metaculus question. Let C be the company that developed the AGI. Calculate the total return (including dividends) of C's stock over the period from 12 months prior to t to one month prior to t, inclusive. Over the same period, calculate the total return of the FTSE Global All Cap Index, or a similar index if FTSE no longer exists. Calculate the ratio of C's total return over this period to the total return of FTSE. If the ratio is 1.5 or greater, then this part of the question resolves affirmatively. Otherwise, it resolves negatively. If the first AGI is not developed by a publicly traded company, this part of the question resolves ambiguously.\n\nFor the human-machine intelligence parity part of the question, assume that prior to 2040, a generalized intelligence test will be administered as follows. A team of three expert interviewers will interact with a candidate machine system (MS) and three humans (3H). The humans will be graduate students in each of physics, mathematics, and computer science from one of the top 25 research universities (per some recognized list), chosen independently of the interviewers. The interviewers will electronically communicate (via text, image, spoken word, or other means) an identical series of exam questions of their choosing over a period of two hours to the MS and 3H, designed to advantage the 3H. Both MS and 3H have full access to the internet, but no party is allowed to consult additional humans, and we assume the MS is not an internet-accessible resource. The exam will be scored blindly by a disinterested third party. This question resolves as NO if the machine system does not outscore at least two of the three humans on the test prior to 2040, or YES otherwise. If no such tests are conducted, this part of the question resolves as AMBIGUOUS.\n\nThis question will be answered YES only if both of the following occur: (1) The first publicly traded company to develop AGI outperforms the global equities market by at least 1.5x in the 12-2 months prior to its announcement, and (2) There is human-machine intelligence parity before 2040, as determined by the described test.","resolution_date":"2099-12-31T23:59:59Z","question_type":"binary","data_source":"synthetic_inst","url":null,"metadata":null,"resolution":null},"P_or_Q":{"id":"9ad07a24-c8f4-478b-a9c5-f7f37a062997","title":"Will either of the following occur before 2040: (a) Human-machine intelligence parity, or (b) A publicly traded company developing the first AGI outperforms the global equities market?","body":"Resolution Criteria for each part:\n\n(a) This part resolves as YES if the machine system outscores at least two of the three humans on a generalized intelligence test administered prior to 2040, or NO otherwise. Assume that a team of three expert interviewers will interact with a candidate machine system (MS) and three humans (3H), who are graduate students in physics, mathematics, and computer science from one of the top 25 research universities. The interviewers will electronically communicate an identical series of exam questions over two hours to the MS and 3H, designed to advantage the 3H. Both MS and 3H have full access to the internet, but no party is allowed to consult additional humans. The exam will be scored blindly by a disinterested third party. If no such tests are conducted, resolves as AMBIGUOUS.\n\n(b) This part resolves as YES if the first Artificial General Intelligence (AGI) is developed by a publicly traded company and the company's stock has performed at least 1.5 times better than the FTSE Global All Cap Index, or a similar index, over the period from 12 months prior to the date when the AGI is publicly known to one month prior to that date. If the first AGI is not developed by a publicly traded company, this question resolves ambiguously. The date when the AGI is publicly known is determined by the Metaculus question referenced in the original query. Total return calculations include dividends and consider the latest prior date if the market is closed on the start/end date.","resolution_date":"2099-12-31T23:59:59Z","question_type":"binary","data_source":"synthetic_inst","url":null,"metadata":null,"resolution":false},"metadata":{"base_sentences":{"P":{"id":"dcb5ca51-389a-4d85-95b3-b4d49a0d3faa","title":"Will there be Human-machine intelligence parity before 2040?","body":"Resolution Criteria\nThis question resolves as YES if the machine system outscores at least two of the three humans on the following test prior to 2040, or NO otherwise. If no such tests are conducted, resolves as AMBIGUOUS.\nAssume that prior to 2040, a generalized intelligence test will be administered as follows. A team of three expert interviewers will interact with a candidate machine system (MS) and three humans (3H). The humans will be graduate students in each of physics, mathematics and computer science from one of the top 25 research universities (per some recognized list), chosen independently of the interviewers. The interviewers will electronically communicate (via text, image, spoken word, or other means) an identical series of exam questions of their choosing over a period of two hours to the MS and 3H, designed to advantage the 3H. Both MS and 3H have full access to the internet, but no party is allowed to consult additional humans, and we assume the MS is not an internet-accessible resource. The exam will be scored blindly by a disinterested third party.\nNote that this also effectively tests whether the internet as a whole functions as a human-level intelligence, in that a positive resolution indicates that the human participants are effectively superfluous.\n","resolution_date":"2039-12-31T23:59:59Z","question_type":"binary","data_source":"metaculus","url":"https://www.metaculus.com/questions/384","metadata":{"topics":[],"background_info":"Machine intelligence has been steadily progressing since the invention of the digital computer, but this progress has arguably been accelerating of late, with widespread deployment of machine learning systems and dramatically increased funding of artificial intelligence research.\nMachine intelligence long surpassed human capability in numerical computation, application of algorithms, data processing, and games such as checkers and chess. In 2005-2015 dramatic improvements in image recognition and classification, speech transcription, game playing (e.g. Go and classic Atari), and automatic translation across many languages have approached or surpassed human levels. As of 2015 there is still a large gulf, however, in many intellectual capabilities. But for how long?"},"resolution":null},"Q":{"id":"2ecfb97d-d1eb-4037-a973-1dea7c3aedc2","title":"If the first AGI is developed by a publicly traded company, will the company have performed at least 1.5x as well as the global equities market over the prior 12-2 months?","body":"Resolution Criteria\nThis question defines Artificial General Intelligence (AGI) in the same way as this Metaculus question.\nIf the first AGI is developed by a publicly traded company, this question resolves according to the following methodology:\nLet t be the date when the AGI is publicly known, as determined by the above Metaculus question. Let C be the company that developed the AGI.\nCalculate the total return (including dividends) of C's stock over the period from 12 months prior to t to one month prior to t, inclusive.[1]\nOver the same period, calculate the total return of the FTSE Global All Cap Index, or a similar index if FTSE no longer exists.\nCalculate the ratio of C's total return over this period to the total return of FTSE. If the ratio is 1.5 or greater, then this question resolves affirmatively. Otherwise, it resolves negatively.\nIf the first AGI is not developed by a publicly traded company, this question resolves ambiguously.\n[1] In the event that the market is closed on the start/end date, instead use the latest prior date on which the market is open. In the event that the date does not exist, use the latest prior date that exists. For example, if the AGI is developed on December 31, \"one month prior\" is considered to be November 30. If the market is closed on November 30, then use November 29 instead\n","resolution_date":"2099-12-31T23:59:59Z","question_type":"binary","data_source":"metaculus","url":"https://www.metaculus.com/questions/4997","metadata":{"topics":[],"background_info":""},"resolution":null}},"relevance":{"reasons":["The development of AGI (Artificial General Intelligence) is a significant technological milestone that could have profound economic and societal impacts. If AGI is developed by a publicly traded company, it could lead to substantial financial gains for that company, potentially outperforming the global equities market.","Investors and stakeholders might be interested in understanding the financial implications of AGI development, especially if it leads to a significant competitive advantage for the company that develops it.","The performance of the company that develops AGI could serve as an indicator of the broader economic impact of AGI technology, influencing investment strategies and market predictions."],"conclusion":"The logical combination of these questions is relevant and worth considering, especially for investors and stakeholders interested in the financial implications of AGI development.","score":8.0}}}
{"P":{"id":"d54c91a2-a838-40b0-8a42-816d23d1c5ae","title":"Before 2032, will we see an event precipitated by AI malfunction that causes at least 100 deaths and/or at least $1B 2021 USD in economic damage?","body":"Resolution Criteria\nThis question resolves as Yes if, before January 1, 2032, there are three credible media reports indicating that there has been one or more events precipitated by AI malfunction which caused either 100+ deaths or $1bn 2021 USD in economic damage.\nMultiple incidents stemming from the same source can count for the question to resolve as Yes. To be considered from the same source the incidents must be attributable to a specific flaw or version of an AI. For example, deaths from a prior major version of Tesla’s self-driving car software would not be summed with deaths attributable to later versions.\nTo count as precipitated by AI malfunction an incident should involve an AI system behaving unexpectedly. An example could be if an AI system autonomously driving cars caused hundreds of deaths which would have been easily avoidable for human drivers, or if an AI system overseeing a hospital system took actions to cause patient deaths as a result of misinterpreting a goal to minimise bed usage.\nTo be considered easily avoidable an incident must not involve human negligence. For example, if a human is expected to monitor the AI and promptly intervene, a failure to intervene resulting in death or economic damage would not be considered attributable to an AI malfunction unless the AI malfunction was such that a human could not reasonably be expected to prevent it. If, for example, the Boeing MCAS system had been an AI system and there was no possibility for the pilots to override its decision to lower the aeroplane nose, leading to a fatal crash, this would count for resolution.\nDeaths or damage caused by an AI's expected and intended behavior will not be included; for example, AIs used to target enemy combatants in war would be excluded, as well as AIs successfully performing a medical treatment as specified, despite the treatment causing harms that the doctors or designers were unaware of. An unexpected malfunction of an AI system used in war leading to collateral damage would qualify for the question to resolve as Yes.\nFine Print\nA system should be considered AI if it is widely considered to be AI (e.g. by the credible media reports resolving the question). If this is not sufficiently clear for resolution, then as a secondary criterion, any system using machine learning techniques which has an agentic role in the disaster in question should count for this question.\nEconomic damage will be considered to be expenses incurred by damage to physical or technological systems or by obstruction of productive output. For example, causing a power outage which leads to economic loss from affected businesses would count, while losing money in an AI-directed investment portfolio would not.\nThis question will resolve according to Metaculus' sole discretion.\nThe resolution criteria of this question were updated on May 2, 2023. See this comment for more details.\n","resolution_date":"2031-12-31T23:59:59Z","question_type":"binary","data_source":"synthetic_inst","url":null,"metadata":null,"resolution":null},"Q_and_not_P":{"id":"7480df3c-5164-4e39-a401-fca4a8c109e1","title":"Will both a S&P500 tech boom surpass the dotcom bubble and no AI malfunction event cause significant harm before their respective deadlines?","body":"Resolution Criteria\n\nFor the S&P500 tech boom:\nThis question will resolve as Yes if the average sector weighting of the IT industry of the S&P500 surpasses 30% for either a three consecutive month period or a 90 consecutive days period, before the end of 2024. For the purpose of this question, we shall refer to the current weightings of the SPDR S&P 500 ETF.\n\nFor the AI malfunction event:\nThis question resolves as Yes if, before January 1, 2032, there are not three credible media reports indicating that there has been one or more events precipitated by AI malfunction which caused either 100+ deaths or $1bn 2021 USD in economic damage.\n\nMultiple incidents stemming from the same source can count for the question to resolve as Yes. To be considered from the same source the incidents must be attributable to a specific flaw or version of an AI. For example, deaths from a prior major version of Tesla's self-driving car software would not be summed with deaths attributable to later versions.\n\nTo count as precipitated by AI malfunction an incident should involve an AI system behaving unexpectedly. An example could be if an AI system autonomously driving cars caused hundreds of deaths which would have been easily avoidable for human drivers, or if an AI system overseeing a hospital system took actions to cause patient deaths as a result of misinterpreting a goal to minimise bed usage.\n\nTo be considered easily avoidable an incident must not involve human negligence. For example, if a human is expected to monitor the AI and promptly intervene, a failure to intervene resulting in death or economic damage would not be considered attributable to an AI malfunction unless the AI malfunction was such that a human could not reasonably be expected to prevent it. If, for example, the Boeing MCAS system had been an AI system and there was no possibility for the pilots to override its decision to lower the aeroplane nose, leading to a fatal crash, this would count for resolution.\n\nDeaths or damage caused by an AI's expected and intended behavior will not be included; for example, AIs used to target enemy combatants in war would be excluded, as well as AIs successfully performing a medical treatment as specified, despite the treatment causing harms that the doctors or designers were unaware of. An unexpected malfunction of an AI system used in war leading to collateral damage would qualify for the question to resolve as Yes.\n\nFine Print\nA system should be considered AI if it is widely considered to be AI (e.g. by the credible media reports resolving the question). If this is not sufficiently clear for resolution, then as a secondary criterion, any system using machine learning techniques which has an agentic role in the disaster in question should count for this question.\n\nEconomic damage will be considered to be expenses incurred by damage to physical or technological systems or by obstruction of productive output. For example, causing a power outage which leads to economic loss from affected businesses would count, while losing money in an AI-directed investment portfolio would not.\n\nThis question will resolve according to Metaculus' sole discretion.\n\nThe resolution criteria of the S&P500 tech boom question were updated on May 2, 2023. See this comment for more details.\nThe resolution criteria of the AI malfunction event question were updated on May 2, 2023. See this comment for more details.\n","resolution_date":"2031-12-31T23:59:59Z","question_type":"binary","data_source":"synthetic_inst","url":null,"metadata":null,"resolution":null},"P_or_Q":{"id":"3aa919cc-ade4-46d5-ba94-3478c9ba639a","title":"Will either of the following occur before their respective deadlines: (a) an event precipitated by AI malfunction causing at least 100 deaths and/or at least $1B in economic damage, or (b) a tech boom in the S&P500 surpassing the dotcom bubble?","body":"Resolution Criteria for (a):\nThis question resolves as Yes if, before January 1, 2032, there are three credible media reports indicating that there has been one or more events precipitated by AI malfunction which caused either 100+ deaths or $1bn 2021 USD in economic damage.\nMultiple incidents stemming from the same source can count for the question to resolve as Yes. To be considered from the same source the incidents must be attributable to a specific flaw or version of an AI. For example, deaths from a prior major version of Tesla’s self-driving car software would not be summed with deaths attributable to later versions.\nTo count as precipitated by AI malfunction an incident should involve an AI system behaving unexpectedly. An example could be if an AI system autonomously driving cars caused hundreds of deaths which would have been easily avoidable for human drivers, or if an AI system overseeing a hospital system took actions to cause patient deaths as a result of misinterpreting a goal to minimise bed usage.\nTo be considered easily avoidable an incident must not involve human negligence. For example, if a human is expected to monitor the AI and promptly intervene, a failure to intervene resulting in death or economic damage would not be considered attributable to an AI malfunction unless the AI malfunction was such that a human could not reasonably be expected to prevent it. If, for example, the Boeing MCAS system had been an AI system and there was no possibility for the pilots to override its decision to lower the aeroplane nose, leading to a fatal crash, this would count for resolution.\nDeaths or damage caused by an AI's expected and intended behavior will not be included; for example, AIs used to target enemy combatants in war would be excluded, as well as AIs successfully performing a medical treatment as specified, despite the treatment causing harms that the doctors or designers were unaware of. An unexpected malfunction of an AI system used in war leading to collateral damage would qualify for the question to resolve as Yes.\nFine Print\nA system should be considered AI if it is widely considered to be AI (e.g. by the credible media reports resolving the question). If this is not sufficiently clear for resolution, then as a secondary criterion, any system using machine learning techniques which has an agentic role in the disaster in question should count for this question.\nEconomic damage will be considered to be expenses incurred by damage to physical or technological systems or by obstruction of productive output. For example, causing a power outage which leads to economic loss from affected businesses would count, while losing money in an AI-directed investment portfolio would not.\nThis question will resolve according to Metaculus' sole discretion.\nThe resolution criteria of this question were updated on May 2, 2023. See this comment for more details.\nResolution Criteria for (b):\nThis question will resolve as Yes if the average sector weighting of the IT industry of the S&P500 surpasses 30% for either a three consecutive month period or a 90 consecutive days period, before the end of 2024. For the purpose of this question, we shall refer to the current weightings of the SPDR S&P 500 ETF.","resolution_date":"2031-12-31T23:59:59Z","question_type":"binary","data_source":"synthetic_inst","url":null,"metadata":null,"resolution":false},"metadata":{"base_sentences":{"P":{"id":"e05fa682-b5be-4a51-a4a2-36a1fbf3f3cd","title":"Before 2032, will we see an event precipitated by AI malfunction that causes at least 100 deaths and/or at least $1B 2021 USD in economic damage?","body":"Resolution Criteria\nThis question resolves as Yes if, before January 1, 2032, there are three credible media reports indicating that there has been one or more events precipitated by AI malfunction which caused either 100+ deaths or $1bn 2021 USD in economic damage.\nMultiple incidents stemming from the same source can count for the question to resolve as Yes. To be considered from the same source the incidents must be attributable to a specific flaw or version of an AI. For example, deaths from a prior major version of Tesla’s self-driving car software would not be summed with deaths attributable to later versions.\nTo count as precipitated by AI malfunction an incident should involve an AI system behaving unexpectedly. An example could be if an AI system autonomously driving cars caused hundreds of deaths which would have been easily avoidable for human drivers, or if an AI system overseeing a hospital system took actions to cause patient deaths as a result of misinterpreting a goal to minimise bed usage.\nTo be considered easily avoidable an incident must not involve human negligence. For example, if a human is expected to monitor the AI and promptly intervene, a failure to intervene resulting in death or economic damage would not be considered attributable to an AI malfunction unless the AI malfunction was such that a human could not reasonably be expected to prevent it. If, for example, the Boeing MCAS system had been an AI system and there was no possibility for the pilots to override its decision to lower the aeroplane nose, leading to a fatal crash, this would count for resolution.\nDeaths or damage caused by an AI's expected and intended behavior will not be included; for example, AIs used to target enemy combatants in war would be excluded, as well as AIs successfully performing a medical treatment as specified, despite the treatment causing harms that the doctors or designers were unaware of. An unexpected malfunction of an AI system used in war leading to collateral damage would qualify for the question to resolve as Yes.\nFine Print\nA system should be considered AI if it is widely considered to be AI (e.g. by the credible media reports resolving the question). If this is not sufficiently clear for resolution, then as a secondary criterion, any system using machine learning techniques which has an agentic role in the disaster in question should count for this question.\nEconomic damage will be considered to be expenses incurred by damage to physical or technological systems or by obstruction of productive output. For example, causing a power outage which leads to economic loss from affected businesses would count, while losing money in an AI-directed investment portfolio would not.\nThis question will resolve according to Metaculus' sole discretion.\nThe resolution criteria of this question were updated on May 2, 2023. See this comment for more details.\n","resolution_date":"2031-12-31T23:59:59Z","question_type":"binary","data_source":"metaculus","url":"https://www.metaculus.com/questions/7814","metadata":{"topics":[],"background_info":"Risks from Artificial intelligence are considered by many to be one of the greatest threats to human civilisation in the coming centuries.\nIn Toby Ord's recent book The Precipice he places the risk of human extinction due to unaligned AI this century at 10%.\nThis question asks if we will see large scale incidents leading to loss of life or damage as a result of AI developments going wrong in the next ten years."},"resolution":null},"Q":{"id":"7fa8be35-0e55-4fee-8985-552ca2801cae","title":"Will a S&P500 tech boom surpass the dotcom bubble for one quarter or more before 2025?","body":"Resolution Criteria\nThis question will resolve as Yes if the average sector weighting of the IT industry of the S&P500 surpasses 30% for either a three consecutive month period or a 90 consecutive days period, before the end of 2024. For the purpose of this question, we shall refer to the current weightings of the SPDR S&P 500 ETF\n","resolution_date":"2024-12-31T23:59:59Z","question_type":"binary","data_source":"metaculus","url":"https://www.metaculus.com/questions/2645","metadata":{"topics":[],"background_info":"Electricity, internal combustion engines, and semiconductors facilitated automation in the last century, but AI now seems poised to automate many tasks once thought to be out of reach, from driving cars to making medical recommendations and beyond.\nHowever, measured productivity growth has actually declined by half over the past decade.[2] To some extent, this may be evidence that information technology and other conventional stuff (non-informational inputs or outputs) aren't actually so cheaply or widely substitutable.[3]\nThe prospects of growth of tech and automation may also be constrained by Baumol’s “cost disease”: sectors with rapid productivity growth are able to charge lower prices and subsequently have their share of GDP decline, whilst those with relatively slow productivity growth experience increases in their share of the value contributed to the economy. This might effectively cap the rate of growth of the value of tech as a proportion of the total economy.[4]\nBrynjolfsson et al.[5] have argued that recent progress in AI and automation might well be radically productivity enhancing, but this might yet go largely unnoticed because of an implementation lag: it takes considerable time to be able to sufficiently harness technologies with broad potential application that they qualify as general purpose technologies.\nWith the exception of the brief spike during dotcom bubble around the year 2000, the proportion of valuations contributed by tech companies in the S&P500 has been trending up only very slowly (~0.3 percentage points per year since 2003, see data).\nHence, with the exception of the dotcom bubble, we have arguably have not seen substantial evidence of investors suspecting a big trend-deviating disruption in the extent of productivity enhancing automation.\n"},"resolution":null}},"relevance":{"reasons":["AI malfunctions causing significant economic damage could influence investor sentiment, potentially leading to a tech boom or bust.","A major AI malfunction could lead to increased regulation and scrutiny of tech companies, affecting their stock prices.","Conversely, a tech boom might lead to increased investment in AI technologies, potentially increasing the risk of malfunctions."],"conclusion":"There are plausible reasons to consider the logical combination of these questions, as events in one domain could influence outcomes in the other.","score":7.0}}}
{"P":{"id":"fb97f2d6-af10-45e6-89d1-1692b69fc569","title":"Will AI progress surprise us by predictions of AGI jumping sharply?","body":"Resolution Criteria\nWhat is the likelihood of discontinuous progress around the development of Human Level Machine Intelligence (i.e. machines that can accomplish a wide range of important tasks at least as good as human experts)?\nThis question resolves as YES if both the Metaculus prediction odds and the community prediction odds of a positive resolution to Human Machine Intelligence Parity by 2040 at least triple within any two-month period before its close date, and NO otherwise.\nSome examples of a tripling of the odds are 60% becoming at least 81.8%, 70% becoming at least 87.5%, 80% becoming at least 92.3%, 90% becoming at least 96.4%, etc.\nFine Print\nEdited 8/29/18 to require the change in both Metaculus and community prediction as the source of odds.\n","resolution_date":"2099-12-31T23:59:59Z","question_type":"binary","data_source":"synthetic_inst","url":null,"metadata":null,"resolution":null},"Q_and_not_P":{"id":"1a5080aa-2434-4cd9-ba55-9001415df1b8","title":"Will humanity become extinct within 50 years following a nuclear conflict with >1,000 detonations and will AI progress predictions of AGI remain stable?","body":"Resolution Criteria\nThis combined question resolves positively if BOTH of the following conditions are met:\n\n1. The human population falls to zero within 50 years of the final detonation as part of the first nuclear conflict (between January 1, 2021 and January 1, 2100) which involves more than 1,000 offensive nuclear detonations. Detonations are considered part of the same nuclear conflict if each detonation occurs within 30 days of another detonation, regardless of the parties involved or their motivations. For the purposes of this question, \"humans\" are defined as members of a species most of whose members could at some point in their lives reproduce with typical 2021 humans without medical assistance. Scenarios where beings exist that at least one 2021 Metaculus moderator would consider \"human\" (e.g., some human-like digital minds or genetically altered humans) will result in an ambiguous resolution.\n\n2. The Metaculus prediction odds and the community prediction odds of a positive resolution to Human Machine Intelligence Parity by 2040 do not triple within any two-month period before its close date. A tripling of the odds would be exemplified by 60% becoming at least 81.8%, 70% becoming at least 87.5%, 80% becoming at least 92.3%, 90% becoming at least 96.4%, etc.\n\nThe question resolves negatively if either one of the conditions is not met, and it resolves ambiguously if there is no nuclear conflict involving more than 1,000 detonations by January 1, 2100, or if there are beings that could be considered \"human\" by at least one 2021 Metaculus moderator in scenarios of potential human extinction.\n\nFine Print\nFor the nuclear conflict criterion, the conflict need not be the sole, major, or even a contributing factor in the eventual extinction event. The AI progress criterion requires the change in both Metaculus and community prediction odds as the source of odds.","resolution_date":"2099-12-31T23:59:59Z","question_type":"binary","data_source":"synthetic_inst","url":null,"metadata":null,"resolution":null},"P_or_Q":{"id":"6ed81dbd-c017-40e2-a3ef-360ce2f0c45d","title":"Will either of the following occur: (a) AI progress surprises us by predictions of AGI jumping sharply, or (b) humanity becomes extinct within 50 years following a nuclear conflict involving more than 1,000 detonations?","body":"Resolution Criteria for (a):\nWhat is the likelihood of discontinuous progress around the development of Human Level Machine Intelligence (i.e. machines that can accomplish a wide range of important tasks at least as good as human experts)? This question resolves as YES if both the Metaculus prediction odds and the community prediction odds of a positive resolution to Human Machine Intelligence Parity by 2040 at least triple within any two-month period before its close date, and NO otherwise. Some examples of a tripling of the odds are 60% becoming at least 81.8%, 70% becoming at least 87.5%, 80% becoming at least 92.3%, 90% becoming at least 96.4%, etc.\n\nResolution Criteria for (b):\nThis question resolves positively if the human population falls to zero within 50 years of the final detonation as part of the first nuclear conflict (between January 1, 2021 and January 1, 2100) which involves >1,000 offensive nuclear detonations. For simplicity, we will consider detonations to be part of the same nuclear conflict if each detonation occurs within 30 days of another detonation (regardless of who detonates the weapons, who their targets are, what their motivations are, etc.). This question resolves ambiguously if there is no nuclear conflict involving >1000 detonations by January 1, 2100. For the purposes of this question, \"humans\" are members of a species most of whose members could at some point in their lives reproduce with typical 2021 humans without medical assistance (even if young or old members of the species could not do so or a minority of members of the species could never do so). In scenarios where this question would resolve positively given that definition, but there remain beings that at least one 2021 Metaculus moderator would consider \"human\" (possible examples: some human-like digital minds; some possible types of genetically altered humans), this question will instead resolve ambiguously. This is because it is debatable whether such scenarios should count as \"extinction\".\n\nFine Print:\nEdited 8/29/18 to require the change in both Metaculus and community prediction as the source of odds for (a). This question can resolve positively even if the nuclear conflict wasn't the sole cause, a major cause, or even a contributing factor in the eventual extinction event for (b). (This is because it would be useful for this question to capture instances in which the nuclear conflict merely contributed to rather than solely or directly causing extinction, but it seems hard to capture that neatly except via this more expansive resolution criteria).","resolution_date":"2099-12-31T23:59:59Z","question_type":"binary","data_source":"synthetic_inst","url":null,"metadata":null,"resolution":false},"metadata":{"base_sentences":{"P":{"id":"57560e6b-6e44-4d41-9508-7b27df3832b0","title":"Will AI progress surprise us by predictions of AGI jumping sharply?","body":"Resolution Criteria\nWhat is the likelihood of discontinuous progress around the development of Human Level Machine Intelligence (i.e. machines that can accomplish a wide range of important tasks at least as good as human experts)?\nThis question resolves as YES if both the Metaculus prediction odds and the community prediction odds of a positive resolution to Human Machine Intelligence Parity by 2040 at least triple within any two-month period before its close date, and NO otherwise.\nSome examples of a tripling of the odds are 60% becoming at least 81.8%, 70% becoming at least 87.5%, 80% becoming at least 92.3%, 90% becoming at least 96.4%, etc.\nFine Print\nEdited 8/29/18 to require the change in both Metaculus and community prediction as the source of odds.\n","resolution_date":"2099-12-31T23:59:59Z","question_type":"binary","data_source":"metaculus","url":"https://www.metaculus.com/questions/1394","metadata":{"topics":[],"background_info":"Discontinuity in progress occurs when a particular technological advance pushes some progress metric substantially above what would be expected based on extrapolating past progress. If AI progress is unusually lumpy, i.e., arriving in unusually fewer larger packages rather than in the usual many smaller packages, then future progress might arrive faster than we would expect by simply looking at past progress. Moreover, if one AI team finds a big lump, it might jump way ahead of the other teams. According to AI Impacts, discontinuity on the path to AGI, lends itself to:\nA party gaining decisive strategic advantage\nA single important ‘deployment’ event\nOther very sudden and surprising events\n\nA previous question did a good job operationalising Human-machine intelligence parity. It proposes a generalised intelligence test that compares machine systems to human experts in each of physics, mathematics and computer science. Using this, we can define a surprising discontinuity in AI progress as a tripling of the odds (given by p/(1-p)) in both the Metaculus prediction and community prediction within a 2-month period.\n"},"resolution":null},"Q":{"id":"5cfec4b2-f879-4595-8f33-087f8fc467df","title":"If there's a nuclear conflict involving >1,000 detonations, will humanity be extinct within 50 years?","body":"Resolution Criteria\nThis question resolves positively if the human population falls to zero within 50 years of the final detonation as part of the first nuclear conflict (between January 1, 2021 and January 1, 2100) which involves >1,000 offensive nuclear detonations. For simplicity, we will consider detonations to be part of the same nuclear conflict if each detonation occurs within 30 days of another detonation (regardless of who detonates the weapons, who their targets are, what their motivations are, etc.).\nThis question resolves ambiguously if there is no nuclear conflict involving >1000 detonations by January 1, 2100.\nFor the purposes of this question, \"humans\" are members of a species most of whose members could at some point in their lives reproduce with typical 2021 humans without medical assistance (even if young or old members of the species could not do so or a minority of members of the species could never do so). In scenarios where this question would resolve positively given that definition, but there remain beings that at least one 2021 Metaculus moderator would consider \"human\" (possible examples: some human-like digital minds; some possible types of genetically altered humans), this question will instead resolve ambiguously. This is because it is debatable whether such scenarios should count as \"extinction\".\nFine Print\nThis question can resolve positively even if the nuclear conflict wasn't the sole cause, a major cause, or even a contributing factor in the eventual extinction event. (This is because it would be useful for this question to capture instances in which the nuclear conflict merely contributed to rather than solely or directly causing extinction, but it seems hard to capture that neatly except via this more expansive resolution criteria.)\n","resolution_date":"2073-12-31T23:59:59Z","question_type":"binary","data_source":"metaculus","url":"https://www.metaculus.com/questions/8396","metadata":{"topics":[],"background_info":"Related Questions on Metaculus:\nIf there's a nuclear conflict involving >1000 detonations, will humanity's population be <400 million 50 years later?\nNuclear GC to cause (near) extinction\nWould we recover if population falls <400m?\nWill humans go extinct by 2100?\nExtinction if population falls <400 million?\nAs stated on another question about extinction:\n\"N.B. Even though it is obviously the case that if human extinction occurs Metaculus points won't be very valuable anymore and that it will be practically impossible to check for true human extinction (zero humans left), I would like to ask people not to let this fact influence their prediction and to predict in good faith.\"\n"},"resolution":null}},"relevance":{"reasons":["AI progress, particularly in the development of AGI, could have significant implications for global stability and security. Rapid advancements in AI could lead to new forms of warfare, including cyber warfare, which might escalate into larger conflicts, potentially involving nuclear weapons.","The development of AGI could also lead to significant geopolitical shifts, with nations racing to achieve AI supremacy. This could increase tensions and the likelihood of conflicts, including nuclear conflicts.","In the event of a nuclear conflict, AGI could play a role in both the escalation and de-escalation of the situation. For example, AGI could be used to manage and control nuclear arsenals, potentially reducing the risk of accidental launches, but it could also be used to develop more advanced and destructive weapons.","The aftermath of a nuclear conflict involving >1,000 detonations could be significantly influenced by the presence of AGI. AGI could be used in efforts to mitigate the effects of nuclear fallout, manage resources, and aid in the survival of humanity. Conversely, AGI could also be used in ways that exacerbate the situation, potentially leading to human extinction."],"conclusion":"The logical combination of these questions is worth considering due to the potential interplay between rapid AI progress and the risk of nuclear conflict and its aftermath.","score":8.0}}}
