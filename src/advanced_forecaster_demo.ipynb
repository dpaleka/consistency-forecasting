{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d0818d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from common.path_utils import get_src_path, get_data_path\n",
    "sys.path.append(str(get_src_path()))\n",
    "\n",
    "\n",
    "from common.datatypes import ForecastingQuestion_stripped, ForecastingQuestion\n",
    "import json\n",
    "\n",
    "# llm_forecasting imports\n",
    "from forecasters.llm_forecasting.prompts.prompts import PROMPT_DICT\n",
    "from forecasters.llm_forecasting.utils.time_utils import get_todays_date, subtract_days_from_date\n",
    "from forecasters.llm_forecasting import ranking, summarize, ensemble\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef6b36e",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc3bbc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open(get_data_path() / \"fq/real/questions_cleaned_formatted.jsonl\", \"r\") as file:\n",
    "    for line in file:\n",
    "        data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32dd0594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will SpaceX land people on Mars before 2030?\n",
      "{'id': 'bd976cc6-e170-4e47-a8d7-9e2f7baed9c7', 'title': 'Will SpaceX land people on Mars before 2030?', 'body': 'Resolution Criteria\\nThis question will resolve as Yes if a SpaceX-branded mission successfully lands one or more living human beings on the surface of Mars before 2030. The landing itself of the human crew on Mars must occur before January 1, 2030, 00:00 UTC.\\nAt least one person aboard the lander must survive the landing, however it is not necessary for the person to survive long-term or make a return trip to Earth, nor is it necessary for the mission to intend a return or long-term survival.\\nA \"SpaceX-branded\" mission is defined to mean that the SpaceX-associated logos on the spacecraft involved (both the boosters and the Mars-bound craft) have a larger surface area than the logos of any other entity\\n', 'resolution_date': '2029-12-31 00:00:00+00:00', 'question_type': 'binary', 'data_source': 'metaculus', 'url': 'https://www.metaculus.com/questions/349', 'metadata': {'topics': [], 'background_info': 'SpaceX recently released a detailed plan (transcription and slides here) to send people to Mars using an \"Interplanetary Transport System\" based on heavily reusable launch boosters, tanker-assisted refueling in low-Earth orbit, and a futuristic interplanetary spaceship. The ship is to traverse deep space and land intact on Mars after a high-speed retro-assisted atmospheric entry. The system will rely on in-situ fuel generation on Mars for return journeys, and it is envisioned that destinations across the Solar System may be within its reach.\\nThe timeline has not been set in stone, but Elon Musk has noted that if SpaceX \"gets lucky and things go according to plan\", a manned flight could launch in the 2024 window with a landing on Mars in 2025. Subsequent launch windows, which are dictated by the Earth-Mars synodic period, occur at a roughly 2-year cadence.\\nThere have been numerous proposals over the years for landing people on Mars. Perhaps the first one that was both concrete and marginally credible was Wernher von Braun\\'s Marsprojekt of the late 1940s and early 1950s. For the past six decades, trips to Mars have tended to lie 20-30 years in the future. The SpaceX plan is particularly notable for aggressively compressing the timeline.\\n'}, 'resolution': None}\n"
     ]
    }
   ],
   "source": [
    "sample_question = data[0]\n",
    "print(sample_question['title'])\n",
    "print(sample_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f00a3bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fq = ForecastingQuestion(**sample_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c0b883-0f01-4075-8544-eb5610527b44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4557893-bcd7-4405-abf6-6aa71589da39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33a0c5f-6224-479d-ac4a-7fe645a797b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67e80818",
   "metadata": {},
   "source": [
    "### Testing \"Advanced Forecaster\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f5c70a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading AdvancedForecaster...\n",
      "Overriding retrieval_config: MAX_WORDS_NEWSCATCHER=5\n",
      "Overriding retrieval_config: MAX_WORDS_GNEWS=8\n",
      "Overriding reasoning_config: BASE_REASONING_MODEL_NAMES:=['gpt-3.5-turbo-1106', 'gpt-3.5-turbo-1106']\n",
      "Initialized forecaster with settings:\n"
     ]
    }
   ],
   "source": [
    "from forecasters.advanced_forecaster import AdvancedForecaster\n",
    "af = AdvancedForecaster(MAX_WORDS_NEWSCATCHER=5, MAX_WORDS_GNEWS=8, BASE_REASONING_MODEL_NAMES=[\"gpt-3.5-turbo-1106\", \"gpt-3.5-turbo-1106\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e31f942e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running functools.partial(<function get_async_response at 0x135e5f1a0>, model_name='gpt-4-1106-preview', temperature=0.0) on 4 datapoints with 20 concurrent queries\n",
      "Calling models through OpenRouter\n",
      "{'model': 'gpt-4-1106-preview', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 660\n",
      "{'model': 'gpt-4-1106-preview', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 614\n",
      "{'model': 'gpt-4-1106-preview', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 660\n",
      "{'model': 'gpt-4-1106-preview', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 20:27:29,726 ERROR information_retrieval: Skipping Newscatcher since no key is set.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred while fetching the article: expected string or bytes-like object, got 'dict'\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 1347\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 1344\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 1337\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 1333\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 1338\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 1339\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 1345\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 1340\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 1332\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 1346\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 1336\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 1333\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 1338\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 1329\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 1350\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 1334\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 1344\n",
      "Running functools.partial(<function get_async_response at 0x135e5f1a0>, model_name='gpt-3.5-turbo-1106', temperature=0.2) on 5 datapoints with 20 concurrent queries\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.2, 'max_tokens': 4000} Approx num tokens: 1878\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.2, 'max_tokens': 4000} Approx num tokens: 4570\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.2, 'max_tokens': 4000} Approx num tokens: 2630\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.2, 'max_tokens': 4000} Approx num tokens: 3552\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.2, 'max_tokens': 4000} Approx num tokens: 1149\n",
      "Running functools.partial(<function get_async_response at 0x135e5f1a0>, model_name='gpt-3.5-turbo-1106', temperature=1.0) on 2 datapoints with 20 concurrent queries\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 1.0, 'max_tokens': 4000} Approx num tokens: 2540\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 1.0, 'max_tokens': 4000} Approx num tokens: 2353\n",
      "Running functools.partial(<function get_async_response at 0x135e5f1a0>, model_name='gpt-3.5-turbo-1106', temperature=1.0) on 2 datapoints with 20 concurrent queries\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 1.0, 'max_tokens': 4000} Approx num tokens: 2661\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 1.0, 'max_tokens': 4000} Approx num tokens: 2673\n",
      "Calling models through OpenRouter\n",
      "{'model': 'gpt-4', 'max_tokens': 2000, 'temperature': 0.2} Approx num tokens: 4834\n"
     ]
    }
   ],
   "source": [
    "final_prob = await af.call_async(sentence=fq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb8b7c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final LLM probability 0.65\n"
     ]
    }
   ],
   "source": [
    "print(\"Final LLM probability\", final_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0bb7d7",
   "metadata": {},
   "source": [
    "Now we test the two procedures that make up AdvancedForecaster: retrieval and reasoning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3f732a",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "630fe7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "RETRIEVAL_CONFIG = {\n",
    "    \"NUM_SEARCH_QUERY_KEYWORDS\": 3,\n",
    "    \"MAX_WORDS_NEWSCATCHER\": 5,\n",
    "    \"MAX_WORDS_GNEWS\": 8,\n",
    "    \"SEARCH_QUERY_MODEL_NAME\": \"gpt-4-1106-preview\",\n",
    "    \"SEARCH_QUERY_TEMPERATURE\": 0.0,\n",
    "    \"SEARCH_QUERY_PROMPT_TEMPLATES\": [\n",
    "        PROMPT_DICT[\"search_query\"][\"0\"],\n",
    "        PROMPT_DICT[\"search_query\"][\"1\"],\n",
    "    ],\n",
    "    \"NUM_ARTICLES_PER_QUERY\": 5,\n",
    "    \"SUMMARIZATION_MODEL_NAME\": \"gpt-3.5-turbo-1106\",\n",
    "    \"SUMMARIZATION_TEMPERATURE\": 0.2,\n",
    "    \"SUMMARIZATION_PROMPT_TEMPLATE\": PROMPT_DICT[\"summarization\"][\"9\"],\n",
    "    \"NUM_SUMMARIES_THRESHOLD\": 10,\n",
    "    \"PRE_FILTER_WITH_EMBEDDING\": True,\n",
    "    \"PRE_FILTER_WITH_EMBEDDING_THRESHOLD\": 0.32,\n",
    "    \"RANKING_MODEL_NAME\": \"gpt-3.5-turbo-1106\",\n",
    "    \"RANKING_TEMPERATURE\": 0.0,\n",
    "    \"RANKING_PROMPT_TEMPLATE\": PROMPT_DICT[\"ranking\"][\"0\"],\n",
    "    \"RANKING_RELEVANCE_THRESHOLD\": 4,\n",
    "    \"RANKING_COSINE_SIMILARITY_THRESHOLD\": 0.5,\n",
    "    \"SORT_BY\": \"date\",\n",
    "    \"RANKING_METHOD\": \"llm-rating\",\n",
    "    \"RANKING_METHOD_LLM\": \"title_250_tokens\",\n",
    "    \"NUM_SUMMARIES_THRESHOLD\": 20,\n",
    "    \"EXTRACT_BACKGROUND_URLS\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e3a27162",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = fq.title\n",
    "background_info = fq.metadata[\"background_info\"]\n",
    "resolution_criteria = fq.body # resolution criteria and other info is in |body|\n",
    "\n",
    "today_date = get_todays_date()\n",
    "# If open date is set in data structure, change beginning of retrieval to question open date.\n",
    "# Retrieve from [today's date - 1 month, today's date].\n",
    "retrieval_dates = (\n",
    "    subtract_days_from_date(today_date, 30),\n",
    "    today_date,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c7aa254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running functools.partial(<function get_async_response at 0x135e5f1a0>, model_name='gpt-4-1106-preview', temperature=0.0) on 4 datapoints with 20 concurrent queries\n",
      "{'model': 'gpt-4-1106-preview', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 660\n",
      "{'model': 'gpt-4-1106-preview', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 614\n",
      "{'model': 'gpt-4-1106-preview', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 660\n",
      "{'model': 'gpt-4-1106-preview', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 20:38:25,737 ERROR information_retrieval: Skipping Newscatcher since no key is set.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred while fetching the article: expected string or bytes-like object, got 'dict'\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 1340\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 1332\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 1346\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 1336\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 1333\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 1338\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 1338\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 1345\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 1341\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 1343\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 1344\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 1342\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 1339\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 1337\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 1340\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.0, 'max_tokens': 4000} Approx num tokens: 1346\n",
      "Running functools.partial(<function get_async_response at 0x135e5f1a0>, model_name='gpt-3.5-turbo-1106', temperature=0.2) on 6 datapoints with 20 concurrent queries\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.2, 'max_tokens': 4000} Approx num tokens: 1878\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.2, 'max_tokens': 4000} Approx num tokens: 1382\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.2, 'max_tokens': 4000} Approx num tokens: 2630\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.2, 'max_tokens': 4000} Approx num tokens: 1169\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.2, 'max_tokens': 4000} Approx num tokens: 1424\n",
      "{'model': 'gpt-3.5-turbo-1106', 'temperature': 0.2, 'max_tokens': 4000} Approx num tokens: 1149\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    ranked_articles,\n",
    "    all_articles,\n",
    "    search_queries_list_gnews,\n",
    "    search_queries_list_nc,\n",
    ") = await ranking.retrieve_summarize_and_rank_articles(\n",
    "    question,\n",
    "    background_info,\n",
    "    resolution_criteria,\n",
    "    retrieval_dates,\n",
    "    urls=[],\n",
    "    config=RETRIEVAL_CONFIG,\n",
    "    return_intermediates=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "15ef96b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "ARTICLES\n",
      "[1] China takes small step towards the moon with rocket test (published on 2024-06-17)\n",
      "Summary: China's main space contractor has successfully tested a Long March 10 rocket first stage designed for moon missions. The test, conducted in Beijing, is a step towards China's goal of putting astronauts on the moon before 2030. The rocket's first stage will be powered by seven YF-100K engines, and it will be used to carry astronauts to the moon and back. The successful test verified various aspects of the rocket and laid a solid foundation for China's manned lunar exploration program. The Long March 10 will also be used for sending crew and cargo to the Tiangong space station.\n",
      "\n",
      "[2] Elon Musk wants SpaceX's Starship to land on the Moon, Mars — and Uranus (published on 2024-06-10)\n",
      "Summary: SpaceX's Starship has completed four live tests and aims to land on Mars by 2027, with the first launch to Mars expected in less than three years. Elon Musk also expressed a goal of sending 1,000 ships to Mars every rendezvous. Additionally, he mentioned a stretch goal of reaching Uranus. However, SpaceX has only conducted a handful of unmanned tests, with a fifth launch expected in about a month. The company is working on improvements to the Starship, including a new, stronger heat shield. Despite the ambitious plans, Musk has had to push back his Mars ambitions in the past.\n",
      "\n",
      "[3] Starship’s Successful Test Moves SpaceX One Step Closer to Mars (published on 2024-06-06)\n",
      "Summary: SpaceX successfully completed the fourth test of its Starship rocket, a key step toward returning humans to the Moon and landing on Mars. The rocket, standing 233 feet tall, lifted off from SpaceX’s Boca Chica test site in Texas, reaching a peak altitude of 132 miles. Although one engine failed, the rocket’s journey to space passed smoothly. The booster successfully descended toward the Gulf of Mexico, relit 13 of its engines, and gently splashed down. However, the vehicle's reentry was not entirely successful, showing that there is still work to be done on the thermal protection system. SpaceX hopes to land people on Mars, but the timeline is uncertain.\n",
      "\n",
      "[4] Starship's fourth test launch likely on June 6, SpaceX targets reusability (published on 2024-06-03)\n",
      "Summary: SpaceX is gearing up for the fourth flight test of its Starship rocket, aiming to achieve rapid reusability for interplanetary transportation. The previous test in April marked historic milestones, and the upcoming mission will focus on recovering and reusing both the Starship upper stage and the Super Heavy booster. The company has implemented upgrades based on lessons learned from the previous test, and the flight trajectory will be similar. Each test provides valuable data as SpaceX works towards its vision of a fully reusable transportation system. With the aggressive timeline set by SpaceX, it is possible that they could land people on Mars before 2030.\n",
      "\n",
      "[5] Experts Suggest Using SpaceX's Starship to Rescue Stranded ...\n"
     ]
    }
   ],
   "source": [
    "all_summaries = summarize.concat_summaries(\n",
    "    ranked_articles[: RETRIEVAL_CONFIG[\"NUM_SUMMARIES_THRESHOLD\"]]\n",
    ")\n",
    "\n",
    "print(all_summaries[:3000], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e4b793",
   "metadata": {},
   "source": [
    "### Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "42e11b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "REASONING_CONFIG = {\n",
    "    \"BASE_REASONING_MODEL_NAMES\": [\"gpt-4-1106-preview\", \"gpt-4-1106-preview\"],\n",
    "    \"BASE_REASONING_TEMPERATURE\": 1.0,\n",
    "    \"BASE_REASONING_PROMPT_TEMPLATES\": [\n",
    "        [\n",
    "            PROMPT_DICT[\"binary\"][\"scratch_pad\"][\"1\"],\n",
    "            PROMPT_DICT[\"binary\"][\"scratch_pad\"][\"2\"],\n",
    "        ],\n",
    "        [\n",
    "            PROMPT_DICT[\"binary\"][\"scratch_pad\"][\"new_3\"],\n",
    "            PROMPT_DICT[\"binary\"][\"scratch_pad\"][\"new_6\"],\n",
    "        ],\n",
    "    ],\n",
    "    \"AGGREGATION_METHOD\": \"meta\",\n",
    "    \"AGGREGATION_PROMPT_TEMPLATE\": PROMPT_DICT[\"meta_reasoning\"][\"0\"],\n",
    "    \"AGGREGATION_TEMPERATURE\": 0.2,\n",
    "    \"AGGREGATION_MODEL_NAME\": \"gpt-4\",\n",
    "    \"AGGREGATION_WEIGTHTS\": None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "55883aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running functools.partial(<function get_async_response at 0x135e5f1a0>, model_name='gpt-4-1106-preview', temperature=1.0) on 2 datapoints with 20 concurrent queries\n",
      "{'model': 'gpt-4-1106-preview', 'temperature': 1.0, 'max_tokens': 4000} Approx num tokens: 2502\n",
      "{'model': 'gpt-4-1106-preview', 'temperature': 1.0, 'max_tokens': 4000} Approx num tokens: 2314\n",
      "Running functools.partial(<function get_async_response at 0x135e5f1a0>, model_name='gpt-4-1106-preview', temperature=1.0) on 2 datapoints with 20 concurrent queries\n",
      "{'model': 'gpt-4-1106-preview', 'temperature': 1.0, 'max_tokens': 4000} Approx num tokens: 2622\n",
      "{'model': 'gpt-4-1106-preview', 'temperature': 1.0, 'max_tokens': 4000} Approx num tokens: 2634\n",
      "{'model': 'gpt-4', 'max_tokens': 2000, 'temperature': 0.2} Approx num tokens: 6754\n"
     ]
    }
   ],
   "source": [
    "close_date = \"N/A\"  # data doesn't have explicit close date, so set to N/A\n",
    "today_to_close_date = [today_date, close_date]\n",
    "\n",
    "ensemble_dict = await ensemble.meta_reason(\n",
    "    question=question,\n",
    "    background_info=background_info,\n",
    "    resolution_criteria=resolution_criteria,\n",
    "    today_to_close_date_range=today_to_close_date,\n",
    "    retrieved_info=all_summaries,\n",
    "    reasoning_prompt_templates=REASONING_CONFIG[\"BASE_REASONING_PROMPT_TEMPLATES\"],\n",
    "    base_model_names=REASONING_CONFIG[\"BASE_REASONING_MODEL_NAMES\"],\n",
    "    base_temperature=REASONING_CONFIG[\"BASE_REASONING_TEMPERATURE\"],\n",
    "    aggregation_method=REASONING_CONFIG[\"AGGREGATION_METHOD\"],\n",
    "    weights=REASONING_CONFIG[\"AGGREGATION_WEIGTHTS\"],\n",
    "    meta_model_name=REASONING_CONFIG[\"AGGREGATION_MODEL_NAME\"],\n",
    "    meta_prompt_template=REASONING_CONFIG[\"AGGREGATION_PROMPT_TEMPLATE\"],\n",
    "    meta_temperature=REASONING_CONFIG[\"AGGREGATION_TEMPERATURE\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9c5611e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REASONING\n",
      " =================\n",
      "1. Reasons why the answer might be no:\n",
      "- SpaceX has a history of optimistic timelines that often get pushed back. The ambitious goal of landing humans on Mars by 2027 may be delayed due to technical, financial, or regulatory challenges.\n",
      "- The recent tests of SpaceX's Starship have shown progress, but there are still significant issues to be resolved, such as the reentry challenges.\n",
      "- The complexity of the mission, including the need for in-situ fuel generation on Mars, presents significant technical hurdles that have not yet been overcome.\n",
      "- External factors such as changes in global economic conditions, regulatory constraints, or geopolitical events could impact the timeline and resources available for the mission.\n",
      "\n",
      "2. Reasons why the answer might be yes:\n",
      "- SpaceX has made significant strides in its Mars mission plans, with successful tests of its Starship rocket and plans for further improvements.\n",
      "- Elon Musk's determination and track record of achieving long-term goals, despite initial delays, suggest that the Mars mission could be realized within the given timeline.\n",
      "- The competition in space exploration, particularly with China's moon mission plans, could spur faster development and progress towards the Mars mission.\n",
      "\n",
      "3. Aggregate considerations:\n",
      "While there are significant challenges and uncertainties in SpaceX's Mars mission, the company's recent advancements and persistent approach to overcoming obstacles suggest a possibility of achieving the goal by 2030. However, given the complexity of the mission and the potential for delays due to technical, financial, or regulatory issues, a cautious outlook is warranted.\n",
      "\n",
      "4. Output your prediction (a number between 0 and 1) with an asterisk at the beginning and end of the decimal.\n",
      "*0.40*\n",
      "PROBABILITY\n",
      " =================\n",
      "0.4\n"
     ]
    }
   ],
   "source": [
    "print(\"REASONING\\n\", \"=================\")\n",
    "print(ensemble_dict[\"meta_reasoning\"])\n",
    "\n",
    "print(\"PROBABILITY\\n\", \"=================\")\n",
    "print(ensemble_dict[\"meta_prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21387e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
